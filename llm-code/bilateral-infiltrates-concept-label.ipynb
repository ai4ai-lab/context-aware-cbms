{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0HKuIqz6mak"
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6131,
     "status": "ok",
     "timestamp": 1717763572973,
     "user": {
      "displayName": "Anish Narain",
      "userId": "17681602453754587772"
     },
     "user_tz": -60
    },
    "id": "8VbkI4zR6MOl",
    "outputId": "8fd49eba-99e4-4f08-e929-937ac1408879"
   },
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J83CiHJ28ywv"
   },
   "source": [
    "Inside terminal run the following:\n",
    "\n",
    "```\n",
    "ollama serve &\n",
    "ollama run llama3\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11450,
     "status": "ok",
     "timestamp": 1717763683780,
     "user": {
      "displayName": "Anish Narain",
      "userId": "17681602453754587772"
     },
     "user_tz": -60
    },
    "id": "iDly6F4x70cy",
    "outputId": "f45f7857-f839-4f74-de9c-5cb8e7b15a58"
   },
   "outputs": [],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24370,
     "status": "ok",
     "timestamp": 1717763714525,
     "user": {
      "displayName": "Anish Narain",
      "userId": "17681602453754587772"
     },
     "user_tz": -60
    },
    "id": "YBKxocof9Hyz",
    "outputId": "25c4f3ad-eb1b-491b-de9d-5c512eb0de63"
   },
   "outputs": [],
   "source": [
    "# Load Google Drive because it stores /content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYn-iYTa6ycW"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1717763719420,
     "user": {
      "displayName": "Anish Narain",
      "userId": "17681602453754587772"
     },
     "user_tz": -60
    },
    "id": "lMw0VBWN9DkQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWQhLQDK638b"
   },
   "source": [
    "# Functions to load data, specify LLM prompt, and perform LLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1717763725216,
     "user": {
      "displayName": "Anish Narain",
      "userId": "17681602453754587772"
     },
     "user_tz": -60
    },
    "id": "PYC4wFzh64z-"
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.fillna('', inplace=True)\n",
    "    return df\n",
    "\n",
    "def select_random_start(num_rows, min_rows=15):\n",
    "    if num_rows < min_rows:\n",
    "        raise ValueError(f\"The dataset must contain at least {min_rows} rows to process.\")\n",
    "    return random.randint(0, num_rows - min_rows)\n",
    "\n",
    "def create_prompt_template():\n",
    "    return PromptTemplate(\n",
    "        template=(\n",
    "            \"Context: You are a clinician receiving chunks of radiology reports for patients in an ICU. Please do the reviewing as quickly as possible.\\n\"\n",
    "            \"Task: Determine if the patient suffered from bilateral infiltrates.\\n\"\n",
    "            \"Instructions: Answer with 'Yes' or 'No'. If there is not enough information, answer 'No'.\\n\"\n",
    "            \"Discharge Text:\\n{radiology_texts}\\n\\n\"\n",
    "            \"Query: Does the chunk of text mention that the patient suffered from bilateral infiltrates? Answer strictly in 'Yes' or 'No'.\"\n",
    "        ),\n",
    "        input_variables=[\"radiology_texts\"]\n",
    "    )\n",
    "\n",
    "def chunk_text(text, chunk_size, overlap):\n",
    "    start = 0\n",
    "    chunks = []\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def check_for_bilateral_infiltrates(radiology_texts, llm, prompt_template, chunk_size, chunk_overlap):\n",
    "    if not radiology_texts:  # Check if radiology_texts is empty or not\n",
    "        return None, \"No radiology text available\", 0  # Return None if there is no radiology_texts entry\n",
    "\n",
    "    chunks = chunk_text(radiology_texts, chunk_size, chunk_overlap)\n",
    "    results = []\n",
    "    for chunk in chunks:\n",
    "        prompt = prompt_template.format(radiology_texts=chunk)\n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            results.append(response.strip())\n",
    "        except Exception as e:\n",
    "            results.append(f\"Error invoking model: {e}\")\n",
    "    bilateral_infiltrates_mentions = [res for res in results if \"Yes\" in res]\n",
    "    if bilateral_infiltrates_mentions:\n",
    "        return \"Yes\", bilateral_infiltrates_mentions[0], len(radiology_texts) # Return bilateral_infiltrates result, explanation, and length of radiology_texts\n",
    "    else:\n",
    "        return \"No\", results[0] if results else \"No sufficient data\", len(radiology_texts) # Return bilateral_infiltrates result, explanation, and length of radiology_texts\n",
    "\n",
    "def process_patients(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file):\n",
    "    processing_time = []\n",
    "    with open(output_csv_file, 'a', newline='') as csvfile, open(progress_report_file, 'a') as report_file:\n",
    "        # Open the CSV file for writing\n",
    "        fieldnames = ['hadm_id', 'radiology_texts_length', 'bilateral_infiltrates_detected', 'time_taken']\n",
    "        # Define the column names\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        # Only write header if the file is empty\n",
    "        if csvfile.tell() == 0:\n",
    "            writer.writeheader()  # Write the header row\n",
    "\n",
    "        for i in range(start_index, start_index + num_patients):\n",
    "            current_hadm_id = df['hadm_id'].values[i]\n",
    "            start_time = time.time()\n",
    "            data = df[df['hadm_id'] == current_hadm_id]\n",
    "            if data.empty:\n",
    "                result = f\"No data found for hadm_id: {current_hadm_id}\"\n",
    "            else:\n",
    "                radiology_texts = data['radiology_texts'].values[0] if 'radiology_texts' in data.columns else ''\n",
    "                bilateral_infiltrates_result, explanation, radiology_texts_length = check_for_bilateral_infiltrates(radiology_texts, llm, prompt_template, chunk_size, chunk_overlap)\n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time - start_time\n",
    "                minutes, seconds = divmod(elapsed_time, 60)\n",
    "                processing_time.append(elapsed_time)\n",
    "                # Write data to CSV file\n",
    "                writer.writerow({\n",
    "                    'hadm_id': current_hadm_id,\n",
    "                    'radiology_texts_length': radiology_texts_length,\n",
    "                    'bilateral_infiltrates_detected': bilateral_infiltrates_result,\n",
    "                    'time_taken': round(elapsed_time)\n",
    "                })\n",
    "                csvfile.flush()  # Flush the buffer to ensure data is written\n",
    "\n",
    "                # Write data to progress report file\n",
    "                report_file.write(f\"Patient Number: {i}, HADM ID: {current_hadm_id}, Radiology Text Length: {radiology_texts_length}, BI Detected: {bilateral_infiltrates_result}, Time Taken: {round(elapsed_time)}\\n\")\n",
    "                report_file.flush()  # Flush the buffer to ensure data is written\n",
    "\n",
    "                print(f\"Processed Patient Number {i}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eq5VseRR7Dfe"
   },
   "source": [
    "# Main (calls all the functions above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `file_path` to the directory containing the cohort notes for all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1181175,
     "status": "ok",
     "timestamp": 1717777205238,
     "user": {
      "displayName": "Anish Narain",
      "userId": "17681602453754587772"
     },
     "user_tz": -60
    },
    "id": "ahusYxXm9kK8",
    "outputId": "87aafb07-b069-4820-ff9c-97e0e08733a1"
   },
   "outputs": [],
   "source": [
    "def main(file_path, model_name, chunk_size, chunk_overlap, output_csv_file, progress_report_file, num_patients):\n",
    "    df = load_data(file_path)\n",
    "    #start_index = select_random_start(len(df))\n",
    "    start_index = 0\n",
    "    prompt_template = create_prompt_template()\n",
    "    llm = Ollama(model=model_name, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "    process_patients(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\n",
    "        file_path='/content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv',\n",
    "        model_name=\"llama3\",\n",
    "        chunk_size=4096,\n",
    "        chunk_overlap=100,\n",
    "        output_csv_file='bilateral-infiltrates-concept-label.csv',  # Change the output file name to a CSV file\n",
    "        progress_report_file='bilateral-infiltrates-concept-label.txt',  # Path to the progress report file\n",
    "        num_patients = 1953\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPjJUzbFPj+rrd0Jj8kWjZq",
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
