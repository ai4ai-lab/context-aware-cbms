{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11286599,"sourceType":"datasetVersion","datasetId":5679533}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:25:48.669398Z","iopub.execute_input":"2025-04-11T17:25:48.669703Z","iopub.status.idle":"2025-04-11T17:25:54.289926Z","shell.execute_reply.started":"2025-04-11T17:25:48.669670Z","shell.execute_reply":"2025-04-11T17:25:54.288703Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mimic-ards/mlhc-ards-cohort-data.csv\")\n\nX_cont = df[['max_norepinephrine_equiv', 'avg_norepinephrine_equiv', 'sofa_cardiovascular_avg_meanbp','sofa_cardiovascular_avg_rate_norepinephrine', 'sofa_respiration_avg_pao2fio2ratio', 'sofa_renal_avg_urineoutput', 'sofa_renal_avg_creatinine', 'sofa_cns_avg_gcs', 'first24hr_cardiovascular_rate_norepinephrine', 'first24hr_cardiovascular_meanbp', 'first24hr_respiration_pao2fio2ratio', 'first24hr_renal_urineoutput','first24hr_renal_creatinine', 'first24hr_cns_gcs', 'sofa_cardiovascular_worst_meanbp', 'sofa_cardiovascular_worst_rate_norepinephrine', 'sofa_respiration_worst_pao2fio2ratio', 'sofa_renal_worst_urineoutput', 'sofa_renal_worst_creatinine', 'sofa_cns_worst_gcs','mech_vent_duration_minutes']]\n\nX_bin = df[['other_respiratory_diseases', 'lung_diseases_due_to_external_agents', 'chronic_lower_respiratory_diseases', 'acute_lower_respiratory_infections', 'influenza_pneumonia', 'upper_respiratory_infections']]\n\nC_cont = df[['c_sofa_avg_cardiovascular', 'c_sofa_avg_respiration', 'c_sofa_avg_renal', 'c_sofa_avg_cns', 'c_first24hr_sofa_max_cardiovascular', 'c_first24hr_sofa_max_respiration', 'c_first24hr_sofa_max_renal', 'c_first24hr_sofa_max_cns', 'c_sofa_max_cardiovascular', 'c_sofa_max_respiration', 'c_sofa_max_renal', 'c_sofa_max_cns']]\n\nC_bin = df[['c_svr_resp_comorbidity', 'c_mod_resp_comorbidity']]\n\nLLM_C = df[['ards_detected','aspiration_detected','bilateral_infiltrates_detected', 'cardiac_arrest_detected', 'cardiac_failure_detected', 'pancreatitis_detected','pneumonia_detected','trali_detected']]\n\nY = df['ARDS_DIAGNOSIS']\n\n\nclass MIMICDataProcessor:\n    def __init__(self, file_path, batch_size=64):\n        self.file_path = file_path\n        self.batch_size = batch_size\n        self.x_scaler = MinMaxScaler()\n        self.c_scaler = MinMaxScaler()\n\n        # Load and clean data\n        self.df = pd.read_csv(file_path)\n    \n        self.X_cont = self.df[['max_norepinephrine_equiv', 'avg_norepinephrine_equiv', 'sofa_cardiovascular_avg_meanbp',\n                          'sofa_cardiovascular_avg_rate_norepinephrine', 'sofa_respiration_avg_pao2fio2ratio',\n                          'sofa_renal_avg_urineoutput', 'sofa_renal_avg_creatinine', 'sofa_cns_avg_gcs', 'first24hr_cardiovascular_meanbp',\n                          'sofa_cardiovascular_worst_meanbp',\n                          'sofa_cardiovascular_worst_rate_norepinephrine', 'sofa_respiration_worst_pao2fio2ratio',\n                          'sofa_renal_worst_urineoutput', 'sofa_cns_worst_gcs',\n                          'mech_vent_duration_minutes']]\n\n        self.X_bin = self.df[['other_respiratory_diseases', 'lung_diseases_due_to_external_agents',\n                         'chronic_lower_respiratory_diseases', 'acute_lower_respiratory_infections',\n                         'influenza_pneumonia', 'upper_respiratory_infections']]\n\n        self.C_cont = self.df[['c_sofa_avg_cardiovascular', 'c_sofa_avg_respiration', 'c_sofa_avg_renal', 'c_sofa_avg_cns',\n                          'c_first24hr_sofa_max_cardiovascular', 'c_first24hr_sofa_max_respiration',\n                          'c_first24hr_sofa_max_renal', 'c_first24hr_sofa_max_cns', 'c_sofa_max_cardiovascular',\n                          'c_sofa_max_respiration', 'c_sofa_max_renal', 'c_sofa_max_cns']]\n\n        self.C_bin = self.df[['c_svr_resp_comorbidity', 'c_mod_resp_comorbidity']]\n\n        self.LLM_C = self.df[['ards_detected', 'aspiration_detected', 'bilateral_infiltrates_detected',\n                         'cardiac_arrest_detected', 'cardiac_failure_detected', 'pancreatitis_detected',\n                         'pneumonia_detected', 'trali_detected']]\n\n        self.Y = self.df['ARDS_DIAGNOSIS']\n        hospital = self.df[['hadm_id']]\n\n        # Split raw data into train/val/test sets\n        X_cont_temp, X_cont_test, X_bin_temp, X_bin_test, C_cont_temp, C_cont_test, C_bin_temp, C_bin_test, \\\n        LLM_C_temp, LLM_C_test, Y_temp, Y_test, hospital_train, hospital_test = train_test_split(\n            self.X_cont, self.X_bin, self.C_cont, self.C_bin, self.LLM_C, self.Y, hospital, test_size=0.20, random_state=42)\n\n        X_cont_train, X_cont_val, X_bin_train, X_bin_val, C_cont_train, C_cont_val, C_bin_train, C_bin_val, \\\n        LLM_C_train, LLM_C_val, Y_train, Y_val = train_test_split(\n            X_cont_temp, X_bin_temp, C_cont_temp, C_bin_temp, LLM_C_temp, Y_temp, test_size=0.25, random_state=42)\n\n        # Impute using median from training data only\n        cont_cols_x = self.X_cont.columns.tolist()\n        cont_cols_c = self.C_cont.columns.tolist()\n        \n        # Compute medians from training data\n        x_medians = X_cont_train.median()\n        c_medians = C_cont_train.median()\n        \n        # Apply to all splits\n        X_cont_train = X_cont_train.fillna(x_medians)\n        X_cont_val = X_cont_val.fillna(x_medians)\n        X_cont_test = X_cont_test.fillna(x_medians)\n        \n        C_cont_train = C_cont_train.fillna(c_medians)\n        C_cont_val = C_cont_val.fillna(c_medians)\n        C_cont_test = C_cont_test.fillna(c_medians)\n\n        # Fit scalers on train data only\n        self.x_scaler.fit(X_cont_train)\n        self.c_scaler.fit(C_cont_train)\n\n        # Transform all splits\n        X_train_scaled = self.x_scaler.transform(X_cont_train)\n        X_val_scaled = self.x_scaler.transform(X_cont_val)\n        X_test_scaled = self.x_scaler.transform(X_cont_test)\n\n        X_train_full = np.concatenate([X_train_scaled, X_bin_train.values.astype(float)], axis=1)\n        X_val_full = np.concatenate([X_val_scaled, X_bin_val.values.astype(float)], axis=1)\n        X_test_full = np.concatenate([X_test_scaled, X_bin_test.values.astype(float)], axis=1)\n\n        C_train_scaled = self.c_scaler.transform(C_cont_train)\n        C_val_scaled = self.c_scaler.transform(C_cont_val)\n        C_test_scaled = self.c_scaler.transform(C_cont_test)\n\n        C_train_full = np.concatenate([C_train_scaled, C_bin_train.values.astype(float)], axis=1)\n        C_val_full = np.concatenate([C_val_scaled, C_bin_val.values.astype(float)], axis=1)\n        C_test_full = np.concatenate([C_test_scaled, C_bin_test.values.astype(float)], axis=1)\n\n        # Convert to tensors\n        self.X_tensor_scaled_train = torch.tensor(X_train_full, dtype=torch.float32)\n        self.X_tensor_scaled_val = torch.tensor(X_val_full, dtype=torch.float32)\n        self.X_tensor_scaled_test = torch.tensor(X_test_full, dtype=torch.float32)\n\n        self.C_tensor_train = torch.tensor(C_train_full, dtype=torch.float32)\n        self.C_tensor_val = torch.tensor(C_val_full, dtype=torch.float32)\n        self.C_tensor_test = torch.tensor(C_test_full, dtype=torch.float32)\n\n        self.LLM_C_tensor_train = torch.tensor(LLM_C_train.values, dtype=torch.float32)\n        self.LLM_C_tensor_val = torch.tensor(LLM_C_val.values, dtype=torch.float32)\n        self.LLM_C_tensor_test = torch.tensor(LLM_C_test.values, dtype=torch.float32)\n\n        self.Y_tensor_train = torch.tensor(Y_train.values, dtype=torch.float32)\n        self.Y_tensor_val = torch.tensor(Y_val.values, dtype=torch.float32)\n        self.Y_tensor_test = torch.tensor(Y_test.values, dtype=torch.float32)\n\n        self.hospital_test = hospital_test\n\n    def create_dataloaders(self):\n        train_dataset = self.MIMICDataset(self.X_tensor_scaled_train, self.C_tensor_train,\n                                          self.LLM_C_tensor_train, self.Y_tensor_train)\n        val_dataset = self.MIMICDataset(self.X_tensor_scaled_val, self.C_tensor_val,\n                                        self.LLM_C_tensor_val, self.Y_tensor_val)\n        test_dataset = self.MIMICDataset(self.X_tensor_scaled_test, self.C_tensor_test,\n                                         self.LLM_C_tensor_test, self.Y_tensor_test)\n\n        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n\n        return train_loader, val_loader, test_loader, self.hospital_test\n\n    def get_features(self):\n        return self.df[['max_norepinephrine_equiv', 'avg_norepinephrine_equiv', 'sofa_cardiovascular_avg_meanbp',\n                        'sofa_cardiovascular_avg_rate_norepinephrine', 'sofa_respiration_avg_pao2fio2ratio',\n                        'sofa_renal_avg_urineoutput', 'sofa_renal_avg_creatinine', 'sofa_cns_avg_gcs',\n                        'first24hr_cardiovascular_rate_norepinephrine', 'first24hr_cardiovascular_meanbp',\n                        'first24hr_respiration_pao2fio2ratio', 'first24hr_renal_urineoutput',\n                        'first24hr_renal_creatinine', 'first24hr_cns_gcs', 'sofa_cardiovascular_worst_meanbp',\n                        'sofa_cardiovascular_worst_rate_norepinephrine', 'sofa_respiration_worst_pao2fio2ratio',\n                        'sofa_renal_worst_urineoutput', 'sofa_renal_worst_creatinine', 'sofa_cns_worst_gcs',\n                        'mech_vent_duration_minutes']].columns.tolist()\n\n    def get_vanilla_concepts(self):\n        return self.df[['c_sofa_avg_cardiovascular', 'c_sofa_avg_respiration', 'c_sofa_avg_renal', 'c_sofa_avg_cns',\n                        'c_first24hr_sofa_max_cardiovascular', 'c_first24hr_sofa_max_respiration',\n                        'c_first24hr_sofa_max_renal', 'c_first24hr_sofa_max_cns', 'c_sofa_max_cardiovascular',\n                        'c_sofa_max_respiration', 'c_sofa_max_renal', 'c_sofa_max_cns',\n                        'c_svr_resp_comorbidity', 'c_mod_resp_comorbidity']].columns.tolist()\n\n    def get_llm_concepts(self):\n        return self.df[['ards_detected', 'aspiration_detected', 'bilateral_infiltrates_detected',\n                        'cardiac_arrest_detected', 'cardiac_failure_detected', 'pancreatitis_detected',\n                        'pneumonia_detected', 'trali_detected']].columns.tolist()\n\n    class MIMICDataset(Dataset):\n        def __init__(self, x, c, llm_c, y):\n            self.x = x\n            self.c = c\n            self.llm_c = llm_c\n            self.y = y\n\n        def __len__(self):\n            return len(self.y)\n\n        def __getitem__(self, idx):\n            return self.x[idx], self.c[idx], self.llm_c[idx], self.y[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:25:54.291224Z","iopub.execute_input":"2025-04-11T17:25:54.291864Z","iopub.status.idle":"2025-04-11T17:25:54.372630Z","shell.execute_reply.started":"2025-04-11T17:25:54.291825Z","shell.execute_reply":"2025-04-11T17:25:54.371513Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class Logistic(nn.Module):\n    def __init__(self, num_features, num_labels):\n        super(Logistic, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_labels, bias=False)\n        \n    def forward(self, x):\n        y_pred = torch.sigmoid(self.layer1(x))\n        return y_pred\n\ndef train_logistic(model, x_size, y_size, learning_rate, weight_decay, epochs, train_loader, val_loader):\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n\n    epochs_count = []\n    label_predictions = []\n    label_val_predictions = []\n    \n    ground_truth_val_y = []\n\n    for epoch in range(epochs):\n        #print(f\"Epoch {epoch+1}/{epochs}\")  # Print current epoch\n        epochs_count.append(epoch)\n\n        # Training Loop\n        model.train()\n\n        for i, batch in enumerate(train_loader):\n            x, c,_, y = batch\n            x, c, y = x.to(device), c.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            \n            y_pred = model(x)\n\n            label_predictions.append(y_pred.detach().cpu().numpy())\n\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss\n\n            loss.backward()\n            optimizer.step()\n        \n        scheduler.step()\n\n        model.eval()\n\n        with torch.no_grad():\n            for x, c,_, y in val_loader:\n                \n                x, c, y = x.to(device), c.to(device), y.to(device)\n\n                ground_truth_val_y.append(y.cpu())\n\n                y_pred = model(x)\n\n                label_val_predictions.append(y_pred.detach().cpu().numpy())\n    \n                y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                    \n                loss = y_loss\n                \n    return model, label_predictions, label_val_predictions, ground_truth_val_y\n\ndef evaluate_label_predictor(ground_truth_y, predicted_y):\n    true_values = np.concatenate(ground_truth_y)\n    predicted_values = np.concatenate(predicted_y).squeeze()\n\n    predicted_classes = (predicted_values > 0.5).astype(int)\n\n    precision = precision_score(true_values, predicted_classes)\n    recall = recall_score(true_values, predicted_classes)\n    f1 = f1_score(true_values, predicted_classes)\n    auc = roc_auc_score(true_values, predicted_classes)\n    accuracy = accuracy_score(true_values, predicted_classes)\n\n    results = {\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1 Score\": f1,\n        \"AUC\": auc,\n        \"Accuracy\": accuracy\n    }\n    return pd.DataFrame(results, index=[\"Metrics\"])\n\ndef test_model_logistic(model, test_loader):\n    model.eval()  \n    criterion = nn.BCELoss()  \n\n    ground_truth_test_y = []\n    label_test_predictions = []\n\n    model.eval()\n            \n    with torch.no_grad():\n        for x, c,_, y in test_loader:\n            \n            x, c, y = x.to(device), c.to(device), y.to(device)\n\n            ground_truth_test_y.append(y.cpu())\n\n            y_pred = model(x)\n\n            label_test_predictions.append(y_pred.detach().cpu().numpy())\n\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss\n            \n    return ground_truth_test_y, label_test_predictions\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfile_path = '/kaggle/input/mimic-ards/mlhc-ards-cohort-data.csv'\nprocessor = MIMICDataProcessor(file_path, batch_size=64)\ntrain_loader, val_loader, test_loader, hospital_test = processor.create_dataloaders()\n\nx_size = processor.X_tensor_scaled_train.shape[1]\nc_size = processor.C_tensor_train.shape[1]\ny_size = 1\nx_to_y_learning_rate = 0.01\nweight_decay = 0.0001\nepochs = 100\nbinary_concept_idx = list(range(processor.C_cont.shape[1], processor.C_cont.shape[1] + processor.C_bin.shape[1]))\n\ncriterion = nn.BCELoss()\n\ntorch.manual_seed(25)\nmodel_log = Logistic(21,1).to(device)\nmodel_log, label_predictions, label_val_predictions, ground_truth_val_y = train_logistic(model_log, x_size, y_size, x_to_y_learning_rate, weight_decay, epochs, train_loader, val_loader)\n\ny_true, pred_log = test_model_logistic(model_log, test_loader)\n\nprint(evaluate_label_predictor(y_true, pred_log))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:25:54.398968Z","iopub.execute_input":"2025-04-11T17:25:54.399382Z","iopub.status.idle":"2025-04-11T17:26:01.427290Z","shell.execute_reply.started":"2025-04-11T17:25:54.399340Z","shell.execute_reply":"2025-04-11T17:26:01.425932Z"}},"outputs":[{"name":"stdout","text":"         Precision    Recall  F1 Score       AUC  Accuracy\nMetrics       0.72  0.692308  0.705882  0.693148  0.693095\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiLabelNN1(nn.Module):\n    def __init__(self, num_features, num_binary_concepts, num_continuous_concepts, num_labels):\n        super(MultiLabelNN1, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_binary_concepts, bias=False)\n        self.layer2 = nn.Linear(num_features, num_continuous_concepts, bias=False)\n        self.layer3 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer4 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        \n    def forward(self, x):\n        binary_c = self.layer1(x)\n        continuous_c = self.layer2(x)\n        \n        binary_c = torch.sigmoid(binary_c)\n        \n        y_pred = torch.sigmoid(self.layer3(binary_c)+self.layer4(continuous_c))\n        return y_pred, binary_c, continuous_c\n\nclass MultiLabelNN2(nn.Module):\n    def __init__(self, num_features, num_binary_concepts, num_continuous_concepts, num_llm_concepts, num_labels):\n        super(MultiLabelNN2, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_binary_concepts, bias=False)\n        self.layer2 = nn.Linear(num_features, num_continuous_concepts, bias=False)\n        self.layer3 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer4 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        self.layer5 = nn.Linear(num_llm_concepts, num_labels, bias=False)\n\n    def forward(self, x, llm_c):\n        binary_c = self.layer1(x)\n        continuous_c = self.layer2(x)\n        \n        binary_c = torch.sigmoid(binary_c)\n        \n        y_pred = torch.sigmoid(self.layer3(binary_c)+self.layer4(continuous_c)+self.layer5(llm_c))\n        return y_pred, binary_c, continuous_c","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:01.428452Z","iopub.execute_input":"2025-04-11T17:26:01.428949Z","iopub.status.idle":"2025-04-11T17:26:01.438611Z","shell.execute_reply.started":"2025-04-11T17:26:01.428916Z","shell.execute_reply":"2025-04-11T17:26:01.437186Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from copy import deepcopy\n\nclass EarlyStopper:\n    def __init__(self, patience=25):\n        self.patience = patience\n        self.counter = 0\n        self.best_score = None\n        self.best_model = None\n\n    def should_stop(self, score, model):\n        if self.best_score is None or score > self.best_score:\n            self.best_score = score\n            self.best_model = deepcopy(model)\n            self.counter = 0\n            return False\n        else:\n            self.counter += 1\n            return self.counter >= self.patience\n\ncriterion = nn.BCELoss()\n\ndef concept_loss(binary_c_pred, continuous_c_pred, vanilla_c, binary_concept_idx):\n\n    bce_loss = nn.BCELoss()\n    mse_loss = nn.MSELoss()\n\n    # print(binary_c_pred.shape,vanilla_c.shape,vanilla_c[:, binary_concept_idx].shape)\n    binary_loss = bce_loss(binary_c_pred,vanilla_c[:, binary_concept_idx]) if binary_concept_idx else 0\n\n    continuous_idx = [i for i in range(vanilla_c.shape[1]) if i not in binary_concept_idx]\n    continuous_loss = mse_loss(continuous_c_pred,vanilla_c[:, continuous_idx]) if continuous_idx else 0\n\n    return binary_loss + continuous_loss\n\ndef train_combined_model(model, x_size, vanilla_c_size, llm_c_size, y_size, learning_rate, epochs, train_loader, val_loader, binary_concept_idx, weight_decay=0.01):\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    #scheduler = StepLR(optimizer, step_size=25, gamma=0.1)\n    stopper = EarlyStopper(30)\n    \n    epochs_count = []\n    binary_c_predictions, continuous_c_predictions, label_predictions = [], [], []\n    binary_c_val_predictions, continuous_c_val_predictions, label_val_predictions = [], [], []\n    \n    ground_truth_val_c, ground_truth_val_y = [], []\n\n    for epoch in range(epochs):\n        #print(f\"Epoch {epoch+1}/{epochs}\")  \n        epochs_count.append(epoch)\n\n        model.train()\n        running_loss = 0.0\n\n        for i, batch in enumerate(train_loader):\n            x, vanilla_c, llm_c, y = batch\n            x, vanilla_c, llm_c, y = x.to(device), vanilla_c.to(device), llm_c.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            y_pred, binary_c_pred, continuous_c_pred = model(x, llm_c)\n\n            binary_c_predictions.append(binary_c_pred.detach().cpu().numpy())\n            continuous_c_predictions.append(continuous_c_pred.detach().cpu().numpy())\n            label_predictions.append(y_pred.detach().cpu().numpy())\n            \n            c_loss = concept_loss(binary_c_pred, continuous_c_pred, vanilla_c, binary_concept_idx)\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n\n            loss = y_loss + 0.5*c_loss\n            \n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        \n        val_loss = 0.0\n\n        with torch.no_grad():\n            for x, vanilla_c, llm_c, y in val_loader:\n                x, vanilla_c, llm_c, y = x.to(device), vanilla_c.to(device), llm_c.to(device), y.to(device)\n\n                ground_truth_val_c.append(vanilla_c.cpu())\n                ground_truth_val_y.append(y.cpu())\n\n                y_pred, binary_c_pred, continuous_c_pred = model(x, llm_c)\n\n                binary_c_val_predictions.append(binary_c_pred.detach().cpu().numpy())\n                continuous_c_val_predictions.append(continuous_c_pred.detach().cpu().numpy())\n                label_val_predictions.append(y_pred.detach().cpu().numpy())\n\n                c_loss = concept_loss(binary_c_pred, continuous_c_pred, vanilla_c, binary_concept_idx)\n                y_loss = criterion(y_pred, y.unsqueeze(1).float())\n\n                val_loss += y_loss + 0.5*c_loss\n\n        if stopper.should_stop(val_loss,model):\n            print(\"Done\")\n            # break\n        #scheduler.step()\n\n    return model, binary_c_predictions, continuous_c_predictions, label_predictions, binary_c_val_predictions, continuous_c_val_predictions, label_val_predictions, ground_truth_val_c, ground_truth_val_y\n\ndef train(model, x_size, c_size, y_size, learning_rate, weight_decay, epochs, train_loader, val_loader, binary_concept_idx):\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    #scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n    stopper = EarlyStopper(30)\n    \n    epochs_count = []\n    binary_c_predictions, continuous_c_predictions, label_predictions = [], [], []\n    binary_c_val_predictions, continuous_c_val_predictions, label_val_predictions = [], [], []\n    \n    ground_truth_val_c, ground_truth_val_y = [], []\n\n    for epoch in range(epochs):\n        #print(f\"Epoch {epoch+1}/{epochs}\")  # Print current epoch\n        epochs_count.append(epoch)\n\n        # Training Loop\n        model.train()\n\n        for i, batch in enumerate(train_loader):\n            x, c,_, y = batch\n            x, c, y = x.to(device), c.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            \n            y_pred, binary_c_pred, continuous_c_pred = model(x)\n\n            binary_c_predictions.append(binary_c_pred.detach().cpu().numpy())\n            continuous_c_predictions.append(continuous_c_pred.detach().cpu().numpy())\n            label_predictions.append(y_pred.detach().cpu().numpy())\n\n            c_loss = concept_loss(binary_c_pred, continuous_c_pred, c, binary_concept_idx)\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss + 0.5*c_loss \n\n            loss.backward()\n            optimizer.step()\n        \n        model.eval()\n\n        with torch.no_grad():\n            val_loss = 0.0\n            for x, c,_, y in val_loader:\n                \n                x, c, y = x.to(device), c.to(device), y.to(device)\n\n                ground_truth_val_c.append(c.cpu())\n                ground_truth_val_y.append(y.cpu())\n\n                y_pred, binary_c_pred, continuous_c_pred = model(x)\n\n                binary_c_val_predictions.append(binary_c_pred.detach().cpu().numpy())\n                continuous_c_val_predictions.append(continuous_c_pred.detach().cpu().numpy())\n                label_val_predictions.append(y_pred.detach().cpu().numpy())\n    \n                c_loss = concept_loss(binary_c_pred, continuous_c_pred, c, binary_concept_idx)\n                y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                    \n                val_loss += y_loss + 0.5*c_loss \n\n        if stopper.should_stop(val_loss,model):\n            print(\"Done\")\n            # break\n        #scheduler.step()\n\n    return model, binary_c_predictions, continuous_c_predictions, label_predictions, binary_c_val_predictions, continuous_c_val_predictions, label_val_predictions, ground_truth_val_c, ground_truth_val_y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:01.439797Z","iopub.execute_input":"2025-04-11T17:26:01.440234Z","iopub.status.idle":"2025-04-11T17:26:01.465150Z","shell.execute_reply.started":"2025-04-11T17:26:01.440192Z","shell.execute_reply":"2025-04-11T17:26:01.463920Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def evaluate_concept_predictor(ground_truth_c, binary_predictions, continuous_predictions, concept_labels, binary_concept_idx):\n    results = []\n\n    total_concepts = len(concept_labels)\n    continuous_idx = [i for i in range(total_concepts) if i not in binary_concept_idx]\n\n    for i, label in enumerate(concept_labels):\n\n        true_values = np.concatenate([c[:, i] if isinstance(c, np.ndarray) else c[:, i].numpy() for c in ground_truth_c])\n        \n        if i in binary_concept_idx:\n\n            predicted_values = np.concatenate([c[:, i - 12] for c in binary_predictions])\n            \n            predicted_classes = (predicted_values > 0.5).astype(int)\n\n            precision = round(precision_score(true_values, predicted_classes, zero_division=0), 3)\n            recall = round(recall_score(true_values, predicted_classes, zero_division=0), 3)\n            f1 = round(f1_score(true_values, predicted_classes, zero_division=0), 3)\n            accuracy = round(accuracy_score(true_values, predicted_classes), 3)\n\n            results.append({\n                \"Label\": label,\n                \"Precision\": precision,\n                \"Recall\": recall,\n                \"F1 Score\": f1,\n                \"Accuracy\": accuracy,\n            })\n\n        else:\n\n            predicted_values = np.concatenate([c[:, i] for c in continuous_predictions])\n            \n            mse = round(mean_squared_error(true_values, predicted_values), 3)\n            mae = round(mean_absolute_error(true_values, predicted_values), 3)\n            rmse = round(mean_squared_error(true_values, predicted_values, squared=False), 3)\n            r2 = round(r2_score(true_values, predicted_values), 3)\n\n            results.append({\n                \"Label\": label,\n                \"MSE\": mse,\n                \"MAE\": mae,\n                \"RMSE\": rmse,\n                \"R2\": r2\n            })\n\n    for label, result in zip(concept_labels, results):\n        print(result)\n            \n    return results\n\n# Label Predictor Evaluation\ndef evaluate_label_predictor(ground_truth_y, predicted_y):\n    true_values = np.concatenate(ground_truth_y)\n    predicted_values = np.concatenate(predicted_y).squeeze()\n\n    predicted_classes = (predicted_values > 0.5).astype(int)\n\n    precision = precision_score(true_values, predicted_classes)\n    recall = recall_score(true_values, predicted_classes)\n    f1 = f1_score(true_values, predicted_classes)\n    auc = roc_auc_score(true_values, predicted_classes)\n    accuracy = accuracy_score(true_values, predicted_classes)\n\n    results = {\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1 Score\": f1,\n        \"AUC\": auc,\n        \"Accuracy\": accuracy\n    }\n    return pd.DataFrame(results, index=[\"Metrics\"])\n\ndef test_model(model, test_loader, binary_concept_idx):\n    model.eval()  \n    criterion = nn.BCELoss()  \n\n    ground_truth_test_c, ground_truth_test_y = [], []\n    binary_c_test_predictions, continuous_c_test_predictions, label_test_predictions = [], [], []\n\n    model.eval()\n            \n    with torch.no_grad():\n        for x, c,_, y in test_loader:\n            \n            x, c, y = x.to(device), c.to(device), y.to(device)\n\n            ground_truth_test_c.append(c.cpu())\n            ground_truth_test_y.append(y.cpu())\n\n            y_pred, binary_c_pred, continuous_c_pred = model(x)\n\n            binary_c_test_predictions.append(binary_c_pred.detach().cpu().numpy())\n            continuous_c_test_predictions.append(continuous_c_pred.detach().cpu().numpy())\n            label_test_predictions.append(y_pred.detach().cpu().numpy())\n\n            c_loss = concept_loss(binary_c_pred, continuous_c_pred, c, binary_concept_idx)\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss + 0.5*c_loss \n            \n    return ground_truth_test_c, ground_truth_test_y, binary_c_test_predictions, continuous_c_test_predictions, label_test_predictions\n\ndef test_combined_model(model, test_loader, binary_concept_idx):\n    model.eval()\n    criterion = nn.BCELoss()\n\n    ground_truth_test_c, ground_truth_test_y = [], []\n    binary_c_test_predictions, continuous_c_test_predictions, label_test_predictions = [], [], []\n\n    with torch.no_grad():\n        for x, c, llm_c, y in test_loader:\n            x, c, llm_c, y = x.to(device), c.to(device), llm_c.to(device), y.to(device)\n\n            ground_truth_test_c.append(c.cpu())\n            ground_truth_test_y.append(y.cpu())\n            \n            y_pred, binary_c_pred, continuous_c_pred = model(x, llm_c)\n\n            binary_c_test_predictions.append(binary_c_pred.detach().cpu().numpy())\n            continuous_c_test_predictions.append(continuous_c_pred.detach().cpu().numpy())\n            label_test_predictions.append(y_pred.detach().cpu().numpy())\n\n            c_loss = concept_loss(binary_c_pred, continuous_c_pred, c, binary_concept_idx)\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss + 0.5*c_loss\n    \n    return ground_truth_test_c, ground_truth_test_y, binary_c_test_predictions, continuous_c_test_predictions, label_test_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:01.466416Z","iopub.execute_input":"2025-04-11T17:26:01.466834Z","iopub.status.idle":"2025-04-11T17:26:01.496002Z","shell.execute_reply.started":"2025-04-11T17:26:01.466791Z","shell.execute_reply":"2025-04-11T17:26:01.494875Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load Data\n# Check if GPU is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfile_path = '/kaggle/input/mimic-ards/mlhc-ards-cohort-data.csv'\nprocessor = MIMICDataProcessor(file_path, batch_size=64)\ntrain_loader, val_loader, test_loader, hospital_test = processor.create_dataloaders()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:01.499676Z","iopub.execute_input":"2025-04-11T17:26:01.500032Z","iopub.status.idle":"2025-04-11T17:26:01.581593Z","shell.execute_reply.started":"2025-04-11T17:26:01.500001Z","shell.execute_reply":"2025-04-11T17:26:01.580365Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"x_size = processor.X_tensor_scaled_train.shape[1]\nc_size = processor.C_tensor_train.shape[1]\ny_size = 1\nx_to_y_learning_rate = 0.3\nweight_decay = 0.0001\nepochs = 100\nbinary_concept_idx = list(range(processor.C_cont.shape[1], processor.C_cont.shape[1] + processor.C_bin.shape[1]))\n\ntorch.manual_seed(25)\nmodel = MultiLabelNN1(21,2,12,1).to(device)\nmodel, binary_c_predictions, continuous_c_predictions, label_predictions, binary_c_val_predictions, continuous_c_val_predictions, label_val_predictions, ground_truth_val_c, ground_truth_val_y = train(model, x_size, c_size, y_size, x_to_y_learning_rate, weight_decay, epochs, train_loader, val_loader, binary_concept_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:01.583906Z","iopub.execute_input":"2025-04-11T17:26:01.584347Z","iopub.status.idle":"2025-04-11T17:26:07.823616Z","shell.execute_reply.started":"2025-04-11T17:26:01.584312Z","shell.execute_reply":"2025-04-11T17:26:07.822281Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Done\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"x_size = processor.X_tensor_scaled_train.shape[1]\nvanilla_c_size = processor.C_tensor_train.shape[1]\nllm_c_size = processor.LLM_C_tensor_train.shape[1]\n\ny_size = 1\nlearning_rate = 0.3\nepochs = 100\nweight_decay = 0.0001\n\ntorch.manual_seed(25)\nmodel2 = MultiLabelNN2(21,2,12,8,1).to(device)\n\nmodel2, binary_c_predictions_llm, continuous_c_predictions_llm, label_predictions_llm, binary_c_val_predictions_llm, continuous_c_val_predictions_llm, label_val_predictions_llm, ground_truth_val_c_llm, ground_truth_val_y_llm = train_combined_model(model2, x_size, vanilla_c_size, llm_c_size, y_size, learning_rate, epochs, train_loader, val_loader, binary_concept_idx, weight_decay)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:07.824757Z","iopub.execute_input":"2025-04-11T17:26:07.825143Z","iopub.status.idle":"2025-04-11T17:26:14.399188Z","shell.execute_reply.started":"2025-04-11T17:26:07.825110Z","shell.execute_reply":"2025-04-11T17:26:14.397882Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Done\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\nDone\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"torch.save(model.state_dict(),\"cbm.pt\")\ntorch.save(model2.state_dict(),\"llm_cbm.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:14.400464Z","iopub.execute_input":"2025-04-11T17:26:14.400871Z","iopub.status.idle":"2025-04-11T17:26:14.408419Z","shell.execute_reply.started":"2025-04-11T17:26:14.400831Z","shell.execute_reply":"2025-04-11T17:26:14.407252Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"c_true, y_true, binary_c_test_predictions, continuous_c_test_predictions, y_pred = test_model(model, test_loader, binary_concept_idx)\n\nc_true_llm, y_true_llm, binary_c_test_predictions_llm, continuous_c_test_predictions_llm, y_pred_llm = test_combined_model(model2, test_loader, binary_concept_idx)\n\nconcept_labels = processor.get_vanilla_concepts()\n\nprint(\"Vanilla\")\nvanilla_c_results = evaluate_concept_predictor(c_true,binary_c_test_predictions, continuous_c_test_predictions,concept_labels, binary_concept_idx)\nprint(\"LLM\")\nllm_c_results = evaluate_concept_predictor(c_true_llm,binary_c_test_predictions_llm, continuous_c_test_predictions_llm, concept_labels, binary_concept_idx)\n\nprint(evaluate_label_predictor(y_true, y_pred))\nprint(evaluate_label_predictor(y_true_llm, y_pred_llm))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:14.409679Z","iopub.execute_input":"2025-04-11T17:26:14.410022Z","iopub.status.idle":"2025-04-11T17:26:14.532327Z","shell.execute_reply.started":"2025-04-11T17:26:14.409992Z","shell.execute_reply":"2025-04-11T17:26:14.531283Z"}},"outputs":[{"name":"stdout","text":"Vanilla\n{'Label': 'c_sofa_avg_cardiovascular', 'MSE': 0.271, 'MAE': 0.19, 'RMSE': 0.521, 'R2': -3.288}\n{'Label': 'c_sofa_avg_respiration', 'MSE': 0.129, 'MAE': 0.271, 'RMSE': 0.359, 'R2': -3.911}\n{'Label': 'c_sofa_avg_renal', 'MSE': 1.864, 'MAE': 0.745, 'RMSE': 1.365, 'R2': -25.232}\n{'Label': 'c_sofa_avg_cns', 'MSE': 0.02, 'MAE': 0.104, 'RMSE': 0.14, 'R2': -3.042}\n{'Label': 'c_first24hr_sofa_max_cardiovascular', 'MSE': 0.421, 'MAE': 0.336, 'RMSE': 0.649, 'R2': -2.045}\n{'Label': 'c_first24hr_sofa_max_respiration', 'MSE': 0.16, 'MAE': 0.324, 'RMSE': 0.4, 'R2': -0.61}\n{'Label': 'c_first24hr_sofa_max_renal', 'MSE': 0.112, 'MAE': 0.275, 'RMSE': 0.335, 'R2': -0.031}\n{'Label': 'c_first24hr_sofa_max_cns', 'MSE': 0.171, 'MAE': 0.242, 'RMSE': 0.413, 'R2': -0.763}\n{'Label': 'c_sofa_max_cardiovascular', 'MSE': 0.653, 'MAE': 0.282, 'RMSE': 0.808, 'R2': -4.729}\n{'Label': 'c_sofa_max_respiration', 'MSE': 0.043, 'MAE': 0.151, 'RMSE': 0.206, 'R2': 0.511}\n{'Label': 'c_sofa_max_renal', 'MSE': 0.26, 'MAE': 0.405, 'RMSE': 0.51, 'R2': -0.696}\n{'Label': 'c_sofa_max_cns', 'MSE': 0.026, 'MAE': 0.129, 'RMSE': 0.161, 'R2': 0.791}\n{'Label': 'c_svr_resp_comorbidity', 'Precision': 0.969, 'Recall': 0.95, 'F1 Score': 0.96, 'Accuracy': 0.98}\n{'Label': 'c_mod_resp_comorbidity', 'Precision': 0.771, 'Recall': 0.955, 'F1 Score': 0.853, 'Accuracy': 0.777}\nLLM\n{'Label': 'c_sofa_avg_cardiovascular', 'MSE': 0.261, 'MAE': 0.174, 'RMSE': 0.511, 'R2': -3.129}\n{'Label': 'c_sofa_avg_respiration', 'MSE': 0.009, 'MAE': 0.073, 'RMSE': 0.094, 'R2': 0.665}\n{'Label': 'c_sofa_avg_renal', 'MSE': 0.052, 'MAE': 0.159, 'RMSE': 0.228, 'R2': 0.268}\n{'Label': 'c_sofa_avg_cns', 'MSE': 0.005, 'MAE': 0.051, 'RMSE': 0.067, 'R2': 0.069}\n{'Label': 'c_first24hr_sofa_max_cardiovascular', 'MSE': 0.434, 'MAE': 0.347, 'RMSE': 0.659, 'R2': -2.145}\n{'Label': 'c_first24hr_sofa_max_respiration', 'MSE': 0.11, 'MAE': 0.269, 'RMSE': 0.332, 'R2': -0.111}\n{'Label': 'c_first24hr_sofa_max_renal', 'MSE': 0.648, 'MAE': 0.393, 'RMSE': 0.805, 'R2': -4.941}\n{'Label': 'c_first24hr_sofa_max_cns', 'MSE': 0.096, 'MAE': 0.256, 'RMSE': 0.31, 'R2': 0.007}\n{'Label': 'c_sofa_max_cardiovascular', 'MSE': 0.55, 'MAE': 0.345, 'RMSE': 0.742, 'R2': -3.827}\n{'Label': 'c_sofa_max_respiration', 'MSE': 0.068, 'MAE': 0.141, 'RMSE': 0.261, 'R2': 0.216}\n{'Label': 'c_sofa_max_renal', 'MSE': 0.171, 'MAE': 0.215, 'RMSE': 0.414, 'R2': -0.117}\n{'Label': 'c_sofa_max_cns', 'MSE': 0.038, 'MAE': 0.139, 'RMSE': 0.195, 'R2': 0.693}\n{'Label': 'c_svr_resp_comorbidity', 'Precision': 0.97, 'Recall': 0.96, 'F1 Score': 0.965, 'Accuracy': 0.982}\n{'Label': 'c_mod_resp_comorbidity', 'Precision': 0.894, 'Recall': 0.955, 'F1 Score': 0.923, 'Accuracy': 0.893}\n         Precision    Recall  F1 Score       AUC  Accuracy\nMetrics   0.740113  0.629808  0.680519  0.689221  0.685422\n         Precision    Recall  F1 Score       AUC  Accuracy\nMetrics   0.771784  0.894231  0.828508  0.796842  0.803069\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Concepts to labels","metadata":{}},{"cell_type":"code","source":"class MultiLabelNN3(nn.Module):\n    def __init__(self, num_binary_concepts, num_continuous_concepts, num_labels):\n        super(MultiLabelNN3, self).__init__()\n        \n        self.layer1 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer2 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        \n    def forward(self, binary_c, continuous_c):\n        \n        y_pred = torch.sigmoid(self.layer1(binary_c)+self.layer2(continuous_c))\n        return y_pred\n        \nclass MultiLabelNN4(nn.Module):\n    def __init__(self, num_binary_concepts, num_continuous_concepts, num_llm_concepts, num_labels):\n        super(MultiLabelNN4, self).__init__()\n        \n        self.layer1 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer2 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        self.layer3 = nn.Linear(num_llm_concepts, num_labels, bias=False)\n\n    def forward(self, binary_c, continuous_c, llm_c):\n        y_pred = torch.sigmoid(self.layer1(binary_c)+self.layer2(continuous_c)+self.layer3(llm_c))\n        return y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:14.533407Z","iopub.execute_input":"2025-04-11T17:26:14.533717Z","iopub.status.idle":"2025-04-11T17:26:14.541652Z","shell.execute_reply.started":"2025-04-11T17:26:14.533690Z","shell.execute_reply":"2025-04-11T17:26:14.540468Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"criterion = nn.BCELoss()\n\ndef train_combined_model_cy(model, model2, learning_rate, epochs, train_loader, val_loader, binary_concept_idx, weight_decay=0.01):\n    \n    optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = StepLR(optimizer, step_size=25, gamma=0.1)\n\n    epochs_count = []\n    label_predictions = []\n    label_val_predictions = []\n    \n    ground_truth_val_y = []\n\n    for epoch in range(epochs):\n        #print(f\"Epoch {epoch+1}/{epochs}\")  \n        epochs_count.append(epoch)\n\n        model.eval()\n        model2.train()\n        running_loss = 0.0\n\n        for i, batch in enumerate(train_loader):\n            x, vanilla_c, llm_c, y = batch\n            x, vanilla_c, llm_c, y = x.to(device), vanilla_c.to(device), llm_c.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            _, binary_c_pred, continuous_c_pred = model(x, llm_c)\n\n            y_pred = model2(binary_c_pred, continuous_c_pred, llm_c)\n\n            label_predictions.append(y_pred.detach().cpu().numpy())\n            \n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n\n            loss = y_loss\n            \n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        model2.eval()\n        running_val_loss = 0.0\n\n        with torch.no_grad():\n            for x, vanilla_c, llm_c, y in val_loader:\n                x, vanilla_c, llm_c, y = x.to(device), vanilla_c.to(device), llm_c.to(device), y.to(device)\n\n                ground_truth_val_y.append(y.cpu())\n\n                _, binary_c_pred, continuous_c_pred = model(x, llm_c)\n                y_pred = model2(binary_c_pred, continuous_c_pred, llm_c)\n                \n                label_val_predictions.append(y_pred.detach().cpu().numpy())\n\n                y_loss = criterion(y_pred, y.unsqueeze(1).float())\n\n                loss = y_loss\n\n        scheduler.step()\n\n    return model2, label_predictions, label_val_predictions, ground_truth_val_y\n\ndef train_cy(model, model2, learning_rate, weight_decay, epochs, train_loader, val_loader, binary_concept_idx):\n    \n    optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n\n    epochs_count = []\n    label_predictions = []\n    label_val_predictions = []\n    \n    ground_truth_val_y = []\n\n    for epoch in range(epochs):\n        #print(f\"Epoch {epoch+1}/{epochs}\")  # Print current epoch\n        epochs_count.append(epoch)\n\n        # Training Loop\n        model.eval()\n        model2.train()\n        \n        for i, batch in enumerate(train_loader):\n            x, c,_, y = batch\n            x, c, y = x.to(device), c.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            \n            _, binary_c_pred, continuous_c_pred = model(x)\n            y_pred = model2(binary_c_pred, continuous_c_pred)\n            \n            label_predictions.append(y_pred.detach().cpu().numpy())\n\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss\n\n            loss.backward()\n            optimizer.step()\n        \n        scheduler.step()\n\n        model.eval()\n        model2.eval()\n\n        with torch.no_grad():\n            for x, c,_, y in val_loader:\n                \n                x, c, y = x.to(device), c.to(device), y.to(device)\n\n                ground_truth_val_y.append(y.cpu())\n\n                _, binary_c_pred, continuous_c_pred = model(x)\n                y_pred = model2(binary_c_pred, continuous_c_pred)\n                \n                label_val_predictions.append(y_pred.detach().cpu().numpy())\n    \n                y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                    \n                loss = y_loss \n                \n    return model2, label_predictions, label_val_predictions, ground_truth_val_y\n\n# Label Predictor Evaluation\ndef evaluate_label_predictor(ground_truth_y, predicted_y):\n    true_values = np.concatenate(ground_truth_y)\n    predicted_values = np.concatenate(predicted_y).squeeze()\n\n    predicted_classes = (predicted_values > 0.5).astype(int)\n\n    precision = precision_score(true_values, predicted_classes)\n    recall = recall_score(true_values, predicted_classes)\n    f1 = f1_score(true_values, predicted_classes)\n    auc = roc_auc_score(true_values, predicted_classes)\n    accuracy = accuracy_score(true_values, predicted_classes)\n\n    results = {\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1 Score\": f1,\n        \"AUC\": auc,\n        \"Accuracy\": accuracy\n    }\n    return pd.DataFrame(results, index=[\"Metrics\"])\n\ndef test_model(model, model2, test_loader, binary_concept_idx):\n    model.eval()  \n    criterion = nn.BCELoss()  \n\n    ground_truth_test_y = []\n    label_test_predictions = []\n\n    model.eval()\n    model2.eval()\n    \n    with torch.no_grad():\n        for x, c,_, y in test_loader:\n            \n            x, c, y = x.to(device), c.to(device), y.to(device)\n\n            ground_truth_test_y.append(y.cpu())\n\n            _, binary_c_pred, continuous_c_pred = model(x)\n            y_pred = model2(binary_c_pred, continuous_c_pred)\n\n            label_test_predictions.append(y_pred.detach().cpu().numpy())\n\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss  \n            \n    return ground_truth_test_y, label_test_predictions\n\ndef test_combined_model(model, model2, test_loader, binary_concept_idx):\n    model.eval()\n    criterion = nn.BCELoss()\n\n    ground_truth_test_y = []\n    label_test_predictions = []\n\n    with torch.no_grad():\n        for x, c, llm_c, y in test_loader:\n            x, c, llm_c, y = x.to(device), c.to(device), llm_c.to(device), y.to(device)\n\n            ground_truth_test_y.append(y.cpu())\n            \n            _, binary_c_pred, continuous_c_pred = model(x, llm_c)\n            y_pred = model2(binary_c_pred, continuous_c_pred, llm_c)\n\n            label_test_predictions.append(y_pred.detach().cpu().numpy())\n\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss\n    \n    return ground_truth_test_y, label_test_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:14.542720Z","iopub.execute_input":"2025-04-11T17:26:14.543028Z","iopub.status.idle":"2025-04-11T17:26:14.568098Z","shell.execute_reply.started":"2025-04-11T17:26:14.543002Z","shell.execute_reply":"2025-04-11T17:26:14.566994Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"x_size = processor.X_tensor_scaled_train.shape[1]\nc_size = processor.C_tensor_train.shape[1]\ny_size = 1\nlearning_rate = 0.01\nweight_decay = 0.0001\nepochs = 100\nbinary_concept_idx = list(range(processor.C_cont.shape[1], processor.C_cont.shape[1] + processor.C_bin.shape[1]))\n\ntorch.manual_seed(25)\nmodel3 = MultiLabelNN3(2,12,1).to(device)\nmodel3, label_predictions_cy, label_val_predictions_cy, ground_truth_val_y_cy = train_cy(model, model3, learning_rate, weight_decay, epochs, train_loader, val_loader, binary_concept_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:14.569289Z","iopub.execute_input":"2025-04-11T17:26:14.569749Z","iopub.status.idle":"2025-04-11T17:26:19.758287Z","shell.execute_reply.started":"2025-04-11T17:26:14.569711Z","shell.execute_reply":"2025-04-11T17:26:19.757190Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"x_size = processor.X_tensor_scaled_train.shape[1]\nvanilla_c_size = processor.C_tensor_train.shape[1]\nllm_c_size = processor.LLM_C_tensor_train.shape[1]\ny_size = 1\nlearning_rate = 0.01\nepochs = 100\nweight_decay = 0.00008\n\ntorch.manual_seed(25)\n\nmodel4 = MultiLabelNN4(2,12,8,1).to(device)\nmodel4, label_predictions_llm_cy, label_val_predictions_llm_cy, ground_truth_val_y_llm_cy = train_combined_model_cy(model2, model4, learning_rate, epochs, train_loader, val_loader, binary_concept_idx, weight_decay)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:19.759250Z","iopub.execute_input":"2025-04-11T17:26:19.759594Z","iopub.status.idle":"2025-04-11T17:26:25.032939Z","shell.execute_reply.started":"2025-04-11T17:26:19.759564Z","shell.execute_reply":"2025-04-11T17:26:25.031644Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"y_true3, y_pred3 = test_model(model, model3, test_loader, binary_concept_idx)\n\ny_true4, y_pred4 = test_combined_model(model2, model4, test_loader, binary_concept_idx)\n\nprint(evaluate_label_predictor(y_true3, y_pred3))\nprint(evaluate_label_predictor(y_true4, y_pred4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:25.034002Z","iopub.execute_input":"2025-04-11T17:26:25.034318Z","iopub.status.idle":"2025-04-11T17:26:25.079967Z","shell.execute_reply.started":"2025-04-11T17:26:25.034289Z","shell.execute_reply":"2025-04-11T17:26:25.078928Z"}},"outputs":[{"name":"stdout","text":"         Precision    Recall  F1 Score      AUC  Accuracy\nMetrics     0.7109  0.721154   0.71599  0.69391  0.695652\n         Precision    Recall  F1 Score       AUC  Accuracy\nMetrics    0.77533  0.846154  0.809195  0.783733  0.787724\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.BCELoss()\n\ndef train_combined_model_cy(model, model2, learning_rate, epochs, train_loader, val_loader, binary_concept_idx, weight_decay=0.01):\n    \n    optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = StepLR(optimizer, step_size=25, gamma=0.1)\n\n    epochs_count = []\n    label_predictions = []\n    label_val_predictions = []\n    \n    ground_truth_val_y = []\n\n    for epoch in range(epochs):\n        #print(f\"Epoch {epoch+1}/{epochs}\")  \n        epochs_count.append(epoch)\n\n        model.eval()\n        model2.train()\n        running_loss = 0.0\n\n        for i, batch in enumerate(train_loader):\n            x, vanilla_c, llm_c, y = batch\n            x, vanilla_c, llm_c, y = x.to(device), vanilla_c.to(device), llm_c.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            # _, binary_c_pred, continuous_c_pred = model(x, llm_c)\n            # y_pred = model2(binary_c_pred, continuous_c_pred, llm_c)\n\n            y_pred = model2(vanilla_c[:,12:14], vanilla_c[:,0:12], llm_c)\n\n            label_predictions.append(y_pred.detach().cpu().numpy())\n            \n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n\n            loss = y_loss\n            \n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        model2.eval()\n        running_val_loss = 0.0\n\n        with torch.no_grad():\n            for x, vanilla_c, llm_c, y in val_loader:\n                x, vanilla_c, llm_c, y = x.to(device), vanilla_c.to(device), llm_c.to(device), y.to(device)\n\n                ground_truth_val_y.append(y.cpu())\n\n                # _, binary_c_pred, continuous_c_pred = model(x, llm_c)\n                # y_pred = model2(binary_c_pred, continuous_c_pred, llm_c)\n                \n                y_pred = model2(vanilla_c[:,12:14], vanilla_c[:,0:12], llm_c)\n                \n                label_val_predictions.append(y_pred.detach().cpu().numpy())\n\n                y_loss = criterion(y_pred, y.unsqueeze(1).float())\n\n                loss = y_loss\n\n        scheduler.step()\n\n    return model2, label_predictions, label_val_predictions, ground_truth_val_y\n\ndef train_cy(model, model2, learning_rate, weight_decay, epochs, train_loader, val_loader, binary_concept_idx):\n    \n    optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n\n    epochs_count = []\n    label_predictions = []\n    label_val_predictions = []\n    \n    ground_truth_val_y = []\n\n    for epoch in range(epochs):\n        #print(f\"Epoch {epoch+1}/{epochs}\")  # Print current epoch\n        epochs_count.append(epoch)\n\n        # Training Loop\n        model.eval()\n        model2.train()\n        \n        for i, batch in enumerate(train_loader):\n            x, c,_, y = batch\n            x, c, y = x.to(device), c.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            \n            #_, binary_c_pred, continuous_c_pred = model(x)\n            #y_pred = model2(binary_c_pred, continuous_c_pred)\n\n            y_pred = model2(c[:,12:14], c[:,0:12])\n            \n            label_predictions.append(y_pred.detach().cpu().numpy())\n\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss\n\n            loss.backward()\n            optimizer.step()\n        \n        scheduler.step()\n\n        model.eval()\n        model2.eval()\n\n        with torch.no_grad():\n            for x, c,_, y in val_loader:\n                \n                x, c, y = x.to(device), c.to(device), y.to(device)\n\n                ground_truth_val_y.append(y.cpu())\n\n                #_, binary_c_pred, continuous_c_pred = model(x)\n                #y_pred = model2(binary_c_pred, continuous_c_pred)\n\n                y_pred = model2(c[:,12:14], c[:,0:12])\n                \n                label_val_predictions.append(y_pred.detach().cpu().numpy())\n    \n                y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                    \n                loss = y_loss \n                \n    return model2, label_predictions, label_val_predictions, ground_truth_val_y\n\n# Label Predictor Evaluation\ndef evaluate_label_predictor(ground_truth_y, predicted_y):\n    true_values = np.concatenate(ground_truth_y)\n    predicted_values = np.concatenate(predicted_y).squeeze()\n\n    predicted_classes = (predicted_values > 0.5).astype(int)\n\n    precision = precision_score(true_values, predicted_classes)\n    recall = recall_score(true_values, predicted_classes)\n    f1 = f1_score(true_values, predicted_classes)\n    auc = roc_auc_score(true_values, predicted_classes)\n    accuracy = accuracy_score(true_values, predicted_classes)\n\n    results = {\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1 Score\": f1,\n        \"AUC\": auc,\n        \"Accuracy\": accuracy\n    }\n    return pd.DataFrame(results, index=[\"Metrics\"])\n\ndef test_model(model, model2, test_loader, binary_concept_idx):\n    model.eval()  \n    criterion = nn.BCELoss()  \n\n    ground_truth_test_y = []\n    label_test_predictions = []\n\n    model.eval()\n    model2.eval()\n    \n    with torch.no_grad():\n        for x, c,_, y in test_loader:\n            \n            x, c, y = x.to(device), c.to(device), y.to(device)\n\n            ground_truth_test_y.append(y.cpu())\n\n            _, binary_c_pred, continuous_c_pred = model(x)\n            #y_pred = model2(binary_c_pred, continuous_c_pred)\n\n            y_pred = model2(c[:,12:14], c[:,0:12])\n            \n            label_test_predictions.append(y_pred.detach().cpu().numpy())\n\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss  \n            \n    return ground_truth_test_y, label_test_predictions\n\ndef test_combined_model(model, model2, test_loader, binary_concept_idx):\n    model.eval()\n    criterion = nn.BCELoss()\n\n    ground_truth_test_y = []\n    label_test_predictions = []\n\n    with torch.no_grad():\n        for x, c, llm_c, y in test_loader:\n            x, c, llm_c, y = x.to(device), c.to(device), llm_c.to(device), y.to(device)\n\n            ground_truth_test_y.append(y.cpu())\n            \n            #_, binary_c_pred, continuous_c_pred = model(x, llm_c)\n            #y_pred = model2(binary_c_pred, continuous_c_pred, llm_c)\n\n            y_pred = model2(c[:,12:14], c[:,0:12], llm_c)\n\n            label_test_predictions.append(y_pred.detach().cpu().numpy())\n\n            y_loss = criterion(y_pred, y.unsqueeze(1).float())\n                \n            loss = y_loss\n    \n    return ground_truth_test_y, label_test_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:25.081028Z","iopub.execute_input":"2025-04-11T17:26:25.081321Z","iopub.status.idle":"2025-04-11T17:26:25.104732Z","shell.execute_reply.started":"2025-04-11T17:26:25.081295Z","shell.execute_reply":"2025-04-11T17:26:25.103590Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"x_size = processor.X_tensor_scaled_train.shape[1]\nc_size = processor.C_tensor_train.shape[1]\ny_size = 1\nlearning_rate = 0.01\nweight_decay = 0.0001\nepochs = 100\nbinary_concept_idx = list(range(processor.C_cont.shape[1], processor.C_cont.shape[1] + processor.C_bin.shape[1]))\n\ntorch.manual_seed(25)\nmodel5 = MultiLabelNN3(2,12,1).to(device)\nmodel5, label_predictions_cy, label_val_predictions_cy, ground_truth_val_y_cy = train_cy(model, model5, learning_rate, weight_decay, epochs, train_loader, val_loader, binary_concept_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:25.105954Z","iopub.execute_input":"2025-04-11T17:26:25.106269Z","iopub.status.idle":"2025-04-11T17:26:29.533337Z","shell.execute_reply.started":"2025-04-11T17:26:25.106239Z","shell.execute_reply":"2025-04-11T17:26:29.532114Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"x_size = processor.X_tensor_scaled_train.shape[1]\nvanilla_c_size = processor.C_tensor_train.shape[1]\nllm_c_size = processor.LLM_C_tensor_train.shape[1]\ny_size = 1\nlearning_rate = 0.01\nepochs = 100\nweight_decay = 0.00008\n\ntorch.manual_seed(25)\n\nmodel6 = MultiLabelNN4(2,12,8,1).to(device)\nmodel6, label_predictions_llm_cy, label_val_predictions_llm_cy, ground_truth_val_y_llm_cy = train_combined_model_cy(model2, model6, learning_rate, epochs, train_loader, val_loader, binary_concept_idx, weight_decay)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:29.535631Z","iopub.execute_input":"2025-04-11T17:26:29.535956Z","iopub.status.idle":"2025-04-11T17:26:34.284284Z","shell.execute_reply.started":"2025-04-11T17:26:29.535926Z","shell.execute_reply":"2025-04-11T17:26:34.283123Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"y_true5, y_pred5 = test_model(model, model5, test_loader, binary_concept_idx)\n\ny_true6, y_pred6 = test_combined_model(model2, model6, test_loader, binary_concept_idx)\n\nprint(evaluate_label_predictor(y_true5, y_pred5))\nprint(evaluate_label_predictor(y_true6, y_pred6))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:34.286461Z","iopub.execute_input":"2025-04-11T17:26:34.286804Z","iopub.status.idle":"2025-04-11T17:26:34.331721Z","shell.execute_reply.started":"2025-04-11T17:26:34.286774Z","shell.execute_reply":"2025-04-11T17:26:34.330699Z"}},"outputs":[{"name":"stdout","text":"         Precision    Recall  F1 Score       AUC  Accuracy\nMetrics   0.607759  0.677885  0.640909  0.590308  0.595908\n         Precision    Recall  F1 Score       AUC  Accuracy\nMetrics   0.758197  0.889423  0.818584  0.783509  0.790281\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Completeness Scores","metadata":{}},{"cell_type":"markdown","source":"| Method                         | Precision | Recall   | F1 Score | AUC      | Accuracy | Mutual Information |\n|--------------------------------|-----------|----------|----------|----------|----------|---------------------|\n| x to y (Logistic)  I(y\\|x)    | 0.720000  | 0.692308 | 0.705882 | 0.693148 | 0.693095 | 0.076               |\n| Vanilla cbm  I(y\\|c,x)        | 0.709524  | 0.716346 | 0.712919 | 0.691506 | 0.693095 | 0.075               |\n| Enhanced cbm I(y\\|c,c_LLM,x)  | 0.774775  | 0.826923 | 0.800000 | 0.776850 | 0.780051 | 0.201               |\n| I(y\\|c_true)                  | 0.699531  | 0.716346 | 0.707838 | 0.683310 | 0.685422 | 0.069               |\n| I(y\\|c_true,c_LLM)            | 0.766816  | 0.822115 | 0.793503 | 0.768981 | 0.772379 | 0.155               |\n| I(y\\|c_pred)                  | 0.607759  | 0.677885 | 0.640909 | 0.590308 | 0.595908 | 0.017               |\n| I(y\\|c_pred,c_LLM)            | 0.758197  | 0.889423 | 0.818584 | 0.783509 | 0.790281 | 0.183               |\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mutual_info_score\ndef compute_mutual_information(true_labels, predicted_values):\n    predicted_classes = (predicted_values >= 0.5).astype(int)\n    return mutual_info_score(true_labels, predicted_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:34.332747Z","iopub.execute_input":"2025-04-11T17:26:34.333041Z","iopub.status.idle":"2025-04-11T17:26:34.337970Z","shell.execute_reply.started":"2025-04-11T17:26:34.333016Z","shell.execute_reply":"2025-04-11T17:26:34.336721Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"y_true_labels = np.concatenate([y_true[i] for i in range(7)])\n\ny_pred_log = np.concatenate([pred_log[i] for i in range(7)]).reshape(-1)\ny_pred_cbm = np.concatenate([y_pred[i] for i in range(7)]).reshape(-1)\ny_pred_enhanced_cbm = np.concatenate([y_pred_llm[i] for i in range(7)]).reshape(-1)\n\ny_pred_true_c_cbm = np.concatenate([y_pred3[i] for i in range(7)]).reshape(-1)\ny_pred_pred_c_cbm = np.concatenate([y_pred5[i] for i in range(7)]).reshape(-1)\ny_pred_true_c_enhanced_cbm = np.concatenate([y_pred4[i] for i in range(7)]).reshape(-1)\ny_pred_pred_c_enhanced_cbm = np.concatenate([y_pred6[i] for i in range(7)]).reshape(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:34.343646Z","iopub.execute_input":"2025-04-11T17:26:34.343975Z","iopub.status.idle":"2025-04-11T17:26:34.359611Z","shell.execute_reply.started":"2025-04-11T17:26:34.343948Z","shell.execute_reply":"2025-04-11T17:26:34.358409Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"print(compute_mutual_information(y_true_labels, y_pred_log))\nprint(compute_mutual_information(y_true_labels, y_pred_cbm))\nprint(compute_mutual_information(y_true_labels, y_pred_enhanced_cbm))\nprint(compute_mutual_information(y_true_labels, y_pred_true_c_cbm))\nprint(compute_mutual_information(y_true_labels, y_pred_pred_c_cbm))\nprint(compute_mutual_information(y_true_labels, y_pred_true_c_enhanced_cbm))\nprint(compute_mutual_information(y_true_labels, y_pred_pred_c_enhanced_cbm))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:34.362969Z","iopub.execute_input":"2025-04-11T17:26:34.363333Z","iopub.status.idle":"2025-04-11T17:26:34.407805Z","shell.execute_reply.started":"2025-04-11T17:26:34.363295Z","shell.execute_reply":"2025-04-11T17:26:34.406511Z"}},"outputs":[{"name":"stdout","text":"0.07628173523090204\n0.07417431566551386\n0.20011362806847313\n0.07724125826316114\n0.016890652815561624\n0.17478443565632862\n0.18283874708371112\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FP/FN pairs evaluations","metadata":{}},{"cell_type":"code","source":"binary_c_pred = np.concatenate([binary_c_test_predictions[i] for i in range(7)],axis=0)\ncontinuous_c_pred = np.concatenate([continuous_c_test_predictions[i] for i in range(7)],axis=0)\nbinary_c_pred_llm = np.concatenate([binary_c_test_predictions_llm[i] for i in range(7)],axis=0)\ncontinuous_c_pred_llm = np.concatenate([continuous_c_test_predictions_llm[i] for i in range(7)],axis=0)\n\nc_pred = np.concatenate([binary_c_pred, continuous_c_pred], axis=1)\nc_pred_llm = np.concatenate([binary_c_pred_llm, continuous_c_pred_llm], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:34.409111Z","iopub.execute_input":"2025-04-11T17:26:34.409536Z","iopub.status.idle":"2025-04-11T17:26:34.416933Z","shell.execute_reply.started":"2025-04-11T17:26:34.409472Z","shell.execute_reply":"2025-04-11T17:26:34.415831Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"test_features = []\ntest_concepts = []\ntest_llm_concepts = []\n\nfor data in test_loader:\n    test_features.append(data[0].numpy())\n    test_concepts.append(data[1].numpy())\n    test_llm_concepts.append(data[2].numpy())\n    \ntest_features = np.concatenate([test_features[i] for i in range(7)], axis=0)\ntest_concepts = np.concatenate([test_concepts[i] for i in range(7)], axis=0)\ntest_llm_concepts = np.concatenate([test_llm_concepts[i] for i in range(7)], axis=0)\n\n#c_pred = np.concatenate([c_pred[i] for i in range(7)],axis=0)\ny_pred = np.concatenate([y_pred[i] for i in range(7)],axis=0).reshape(-1)\ny_true = np.concatenate([y_true[i].reshape(-1) for i in range(7)],axis=0)\n\nthreshold = 0.5\n\npredicted_labels = (y_pred >= threshold).astype(int)\n\ntrue_positives_idx = np.where((y_true == 1) & (predicted_labels == 1))[0]\ntrue_negatives_idx = np.where((y_true == 0) & (predicted_labels == 0))[0]\nfalse_positives_idx = np.where((y_true == 0) & (predicted_labels == 1))[0]\nfalse_negatives_idx = np.where((y_true == 1) & (predicted_labels == 0))[0]\n\n#c_pred_llm = np.concatenate([c_pred_llm[i] for i in range(7)],axis=0)\ny_pred_llm = np.concatenate([y_pred_llm[i] for i in range(7)],axis=0).reshape(-1)\ny_true_llm = np.concatenate([y_true_llm[i].reshape(-1) for i in range(7)],axis=0)\n\nthreshold = 0.5\n\npredicted_labels = (y_pred_llm >= threshold).astype(int).reshape(-1)\n\ntrue_positives_idx_llm = np.where((y_true_llm == 1) & (predicted_labels == 1))[0]\ntrue_negatives_idx_llm = np.where((y_true_llm == 0) & (predicted_labels == 0))[0]\nfalse_positives_idx_llm = np.where((y_true_llm == 0) & (predicted_labels == 1))[0]\nfalse_negatives_idx_llm = np.where((y_true_llm == 1) & (predicted_labels == 0))[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:34.418217Z","iopub.execute_input":"2025-04-11T17:26:34.418767Z","iopub.status.idle":"2025-04-11T17:26:34.447852Z","shell.execute_reply.started":"2025-04-11T17:26:34.418713Z","shell.execute_reply":"2025-04-11T17:26:34.446591Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Interventions","metadata":{}},{"cell_type":"markdown","source":"## Interventions over base CBM: Binary concepts","metadata":{}},{"cell_type":"code","source":"class Int1(nn.Module):\n    def __init__(self, num_features, num_binary_concepts, num_continuous_concepts, num_labels):\n        super(Int1, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_binary_concepts, bias=False)\n        self.layer2 = nn.Linear(num_features, num_continuous_concepts, bias=False)\n        self.layer3 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer4 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        \n    def forward(self, x, binary_int):\n        #binary_c = self.layer1(x)\n        continuous_c = self.layer2(x)\n        \n        #binary_c = torch.sigmoid(binary_c)\n        \n        y_pred = torch.sigmoid(self.layer3(binary_int)+self.layer4(continuous_c))\n        return y_pred\n\nmodel_int1 = Int1(26,2,12,1)\n\nfor p1,p2 in zip(model_int1.parameters(),model.parameters()):\n    p1.data = p2.data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:34.449061Z","iopub.execute_input":"2025-04-11T17:26:34.449473Z","iopub.status.idle":"2025-04-11T17:26:34.459556Z","shell.execute_reply.started":"2025-04-11T17:26:34.449430Z","shell.execute_reply":"2025-04-11T17:26:34.458439Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"### Replacement with true values","metadata":{}},{"cell_type":"code","source":"#intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\nintervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n\n        b[int_index] = test_concepts[a][int_index]\n        b = b[-2:]\n        \n        p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx:\n    \n    b = c_pred[a].copy()\n\n    b[12] = test_concepts[a][12]\n    b[13] = test_concepts[a][13]\n\n    b = b[-2:]\n    \n    p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n\nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_positives_idx:\n        \n        b = c_pred[a].copy()\n        b[int_index] = test_concepts[a][int_index]\n\n        b = b[-2:]\n        \n        p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx:\n    b = c_pred[a].copy()\n    \n    b[12] = test_concepts[a][12]\n    b[13] = test_concepts[a][13]\n    b = b[-2:]\n    \n    p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int<0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:34.460611Z","iopub.execute_input":"2025-04-11T17:26:34.460898Z","iopub.status.idle":"2025-04-11T17:26:34.550618Z","shell.execute_reply.started":"2025-04-11T17:26:34.460873Z","shell.execute_reply":"2025-04-11T17:26:34.549426Z"}},"outputs":[{"name":"stdout","text":"Int concept 12 False negatives corrections: 0.07792207792207792 6 77\nInt concept 13 False negatives corrections: 0.3116883116883117 24 77\nFalse negatives corrections: 0.025974025974025976 2 77\nInt concept 12 False positives corrections: 0.0 0 46\nInt concept 13 False positives corrections: 0.021739130434782608 1 46\nFalse positives corrections: 0.021739130434782608 1 46\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-28-fcbff49c8a4a>:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"### Replacement with mean","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n\n        b[int_index] = np.mean(test_concepts,axis=0)[int_index]\n        b = b[-2:]\n        \n        p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx:\n    \n    b = c_pred[a].copy()\n\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    b[13] = np.mean(test_concepts,axis=0)[13]\n\n    b = b[-2:]\n    \n    p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n\nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_positives_idx:\n        \n        b = c_pred[a].copy()\n        b[int_index] = np.mean(test_concepts,axis=0)[int_index]\n\n        b = b[-2:]\n        \n        p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx:\n    b = c_pred[a].copy()\n    \n    b[12] = np.mean(test_concepts,axis=0)[12]\n    b[13] = np.mean(test_concepts,axis=0)[13]\n    b = b[-2:]\n    \n    p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int<0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:34.551741Z","iopub.execute_input":"2025-04-11T17:26:34.552127Z","iopub.status.idle":"2025-04-11T17:26:34.661643Z","shell.execute_reply.started":"2025-04-11T17:26:34.552087Z","shell.execute_reply":"2025-04-11T17:26:34.660318Z"}},"outputs":[{"name":"stdout","text":"Int concept 12 False negatives corrections: 0.33766233766233766 26 77\nInt concept 13 False negatives corrections: 0.33766233766233766 26 77\nFalse negatives corrections: 0.2597402597402597 20 77\nInt concept 12 False positives corrections: 0.0 0 46\nInt concept 13 False positives corrections: 0.021739130434782608 1 46\nFalse positives corrections: 0.0 0 46\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"### Replacement with median","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n\n        b[int_index] = np.median(test_concepts,axis=0)[int_index]\n        b = b[-2:]\n        \n        p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx:\n    \n    b = c_pred[a].copy()\n\n    b[12] = np.median(test_concepts,axis=0)[12]\n    b[13] = np.median(test_concepts,axis=0)[13]\n\n    b = b[-2:]\n    \n    p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n\nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_positives_idx:\n        \n        b = c_pred[a].copy()\n        b[int_index] = np.median(test_concepts,axis=0)[int_index]\n\n        b = b[-2:]\n        \n        p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx:\n    b = c_pred[a].copy()\n    \n    b[12] = np.median(test_concepts,axis=0)[12]\n    b[13] = np.median(test_concepts,axis=0)[13]\n    b = b[-2:]\n    \n    p_int = model_int1(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int<0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:34.662688Z","iopub.execute_input":"2025-04-11T17:26:34.662969Z","iopub.status.idle":"2025-04-11T17:26:34.848397Z","shell.execute_reply.started":"2025-04-11T17:26:34.662943Z","shell.execute_reply":"2025-04-11T17:26:34.847340Z"}},"outputs":[{"name":"stdout","text":"Int concept 12 False negatives corrections: 0.05194805194805195 4 77\nInt concept 13 False negatives corrections: 0.3116883116883117 24 77\nFalse negatives corrections: 0.0 0 77\nInt concept 12 False positives corrections: 0.043478260869565216 2 46\nInt concept 13 False positives corrections: 0.043478260869565216 2 46\nFalse positives corrections: 0.10869565217391304 5 46\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Interventions over base CBM: continuous concepts","metadata":{}},{"cell_type":"markdown","source":"### Replacement with ground truth","metadata":{}},{"cell_type":"code","source":"class Int2(nn.Module):\n    def __init__(self, num_features, num_binary_concepts, num_continuous_concepts, num_labels):\n        super(Int2, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_binary_concepts, bias=False)\n        self.layer2 = nn.Linear(num_features, num_continuous_concepts, bias=False)\n        self.layer3 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer4 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        \n    def forward(self, x, continuous_int):\n        binary_c = self.layer1(x)\n        #continuous_c = self.layer2(x)\n        \n        binary_c = torch.sigmoid(binary_c)\n    \n        y_pred = torch.sigmoid(self.layer3(binary_c)+self.layer4(continuous_int))\n        return y_pred\n\nmodel_int2 = Int2(26,2,12,1)\n\nfor p1,p2 in zip(model_int2.parameters(),model.parameters()):\n    p1.data = p2.data\n\nintervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n#intervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n\n        b[int_index] = test_concepts[a][int_index]\n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx:\n    \n    b = c_pred[a].copy()\n\n    #b[0] = test_concepts[a][0]\n    b[2] = test_concepts[a][2]\n    b[3] = test_concepts[a][3]\n    b[5] = test_concepts[a][5]\n    b[10] = test_concepts[a][10]\n    \n    b = b[:-2]\n    \n    p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n\nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_positives_idx:\n        \n        b = c_pred[a].copy()\n        b[int_index] = test_concepts[a][int_index]\n\n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx:\n    \n    b = c_pred[a].copy()\n\n    b[1] = test_concepts[a][1]\n    b[2] = test_concepts[a][2]\n    b[11] = test_concepts[a][11]\n    \n    b = b[:-2]\n    \n    p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int<0.5:\n        count+=1\n    total+=1\n\nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:34.849529Z","iopub.execute_input":"2025-04-11T17:26:34.849819Z","iopub.status.idle":"2025-04-11T17:26:35.159508Z","shell.execute_reply.started":"2025-04-11T17:26:34.849793Z","shell.execute_reply":"2025-04-11T17:26:35.158421Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.05194805194805195 4 77\nInt concept 1 False negatives corrections: 0.06493506493506493 5 77\nInt concept 2 False negatives corrections: 0.16883116883116883 13 77\nInt concept 3 False negatives corrections: 0.07792207792207792 6 77\nInt concept 4 False negatives corrections: 0.06493506493506493 5 77\nInt concept 5 False negatives corrections: 0.07792207792207792 6 77\nInt concept 6 False negatives corrections: 0.06493506493506493 5 77\nInt concept 7 False negatives corrections: 0.06493506493506493 5 77\nInt concept 8 False negatives corrections: 0.06493506493506493 5 77\nInt concept 9 False negatives corrections: 0.06493506493506493 5 77\nInt concept 10 False negatives corrections: 0.1038961038961039 8 77\nInt concept 11 False negatives corrections: 0.06493506493506493 5 77\nFalse negatives corrections: 0.16883116883116883 13 77\nInt concept 0 False positives corrections: 0.6521739130434783 30 46\nInt concept 1 False positives corrections: 0.8695652173913043 40 46\nInt concept 2 False positives corrections: 0.8913043478260869 41 46\nInt concept 3 False positives corrections: 0.8478260869565217 39 46\nInt concept 4 False positives corrections: 0.8478260869565217 39 46\nInt concept 5 False positives corrections: 0.8260869565217391 38 46\nInt concept 6 False positives corrections: 0.8260869565217391 38 46\nInt concept 7 False positives corrections: 0.8695652173913043 40 46\nInt concept 8 False positives corrections: 0.8695652173913043 40 46\nInt concept 9 False positives corrections: 0.8695652173913043 40 46\nInt concept 10 False positives corrections: 0.7391304347826086 34 46\nInt concept 11 False positives corrections: 0.8913043478260869 41 46\nFalse positives corrections: 0.8695652173913043 40 46\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"### Replacement with mean","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n#intervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n\n        b[int_index] = np.mean(test_concepts,axis=0)[int_index]\n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx:\n    \n    b = c_pred[a].copy()\n\n    #b[0] = np.mean(test_concepts,axis=0)[0]\n    #b[2] = np.mean(test_concepts,axis=0)[2]\n    b[3] = np.mean(test_concepts,axis=0)[3]\n    b[5] = np.mean(test_concepts,axis=0)[5]\n    b[6] = np.mean(test_concepts,axis=0)[6]\n    b[10] = np.mean(test_concepts,axis=0)[10]\n    \n    b = b[:-2]\n    \n    p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n\nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_positives_idx:\n        \n        b = c_pred[a].copy()\n        b[int_index] = np.mean(test_concepts,axis=0)[int_index]\n\n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx:\n    \n    b = c_pred[a].copy()\n\n    b[8] = np.mean(test_concepts,axis=0)[8]\n    b[11] = np.mean(test_concepts,axis=0)[11]\n    \n    b = b[:-2]\n    \n    p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int<0.5:\n        count+=1\n    total+=1\n\nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:35.160628Z","iopub.execute_input":"2025-04-11T17:26:35.160991Z","iopub.status.idle":"2025-04-11T17:26:35.604848Z","shell.execute_reply.started":"2025-04-11T17:26:35.160950Z","shell.execute_reply":"2025-04-11T17:26:35.603879Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.06493506493506493 5 77\nInt concept 1 False negatives corrections: 0.06493506493506493 5 77\nInt concept 2 False negatives corrections: 0.025974025974025976 2 77\nInt concept 3 False negatives corrections: 0.07792207792207792 6 77\nInt concept 4 False negatives corrections: 0.05194805194805195 4 77\nInt concept 5 False negatives corrections: 0.07792207792207792 6 77\nInt concept 6 False negatives corrections: 0.07792207792207792 6 77\nInt concept 7 False negatives corrections: 0.06493506493506493 5 77\nInt concept 8 False negatives corrections: 0.06493506493506493 5 77\nInt concept 9 False negatives corrections: 0.06493506493506493 5 77\nInt concept 10 False negatives corrections: 0.12987012987012986 10 77\nInt concept 11 False negatives corrections: 0.06493506493506493 5 77\nFalse negatives corrections: 0.2597402597402597 20 77\nInt concept 0 False positives corrections: 0.717391304347826 33 46\nInt concept 1 False positives corrections: 0.8695652173913043 40 46\nInt concept 2 False positives corrections: 0.6956521739130435 32 46\nInt concept 3 False positives corrections: 0.8478260869565217 39 46\nInt concept 4 False positives corrections: 0.8695652173913043 40 46\nInt concept 5 False positives corrections: 0.8478260869565217 39 46\nInt concept 6 False positives corrections: 0.8478260869565217 39 46\nInt concept 7 False positives corrections: 0.8695652173913043 40 46\nInt concept 8 False positives corrections: 0.8913043478260869 41 46\nInt concept 9 False positives corrections: 0.8695652173913043 40 46\nInt concept 10 False positives corrections: 0.7608695652173914 35 46\nInt concept 11 False positives corrections: 0.8913043478260869 41 46\nFalse positives corrections: 0.8695652173913043 40 46\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"### Replacement with median","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n#intervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n\n        b[int_index] = np.median(test_concepts,axis=0)[int_index]\n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx:\n    \n    b = c_pred[a].copy()\n\n    b[3] = np.mean(test_concepts,axis=0)[3]\n    b[5] = np.mean(test_concepts,axis=0)[5]\n    b[6] = np.mean(test_concepts,axis=0)[6]\n    b[10] = np.mean(test_concepts,axis=0)[10]\n    \n    b = b[:-2]\n    \n    p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n\nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    count = 0\n    total = 0\n    for a in false_positives_idx:\n        \n        b = c_pred[a].copy()\n        b[int_index] = np.median(test_concepts,axis=0)[int_index]\n\n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx:\n    \n    b = c_pred[a].copy()\n\n    b[1] = np.median(test_concepts,axis=0)[1]\n    b[2] = np.median(test_concepts,axis=0)[2]\n    b[11] = np.median(test_concepts,axis=0)[11]\n    \n    b = b[:-2]\n    \n    p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n\n    if p_int<0.5:\n        count+=1\n    total+=1\n\nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:35.605988Z","iopub.execute_input":"2025-04-11T17:26:35.606399Z","iopub.status.idle":"2025-04-11T17:26:36.314464Z","shell.execute_reply.started":"2025-04-11T17:26:35.606360Z","shell.execute_reply":"2025-04-11T17:26:36.313073Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.06493506493506493 5 77\nInt concept 1 False negatives corrections: 0.06493506493506493 5 77\nInt concept 2 False negatives corrections: 0.012987012987012988 1 77\nInt concept 3 False negatives corrections: 0.07792207792207792 6 77\nInt concept 4 False negatives corrections: 0.06493506493506493 5 77\nInt concept 5 False negatives corrections: 0.07792207792207792 6 77\nInt concept 6 False negatives corrections: 0.07792207792207792 6 77\nInt concept 7 False negatives corrections: 0.06493506493506493 5 77\nInt concept 8 False negatives corrections: 0.05194805194805195 4 77\nInt concept 9 False negatives corrections: 0.06493506493506493 5 77\nInt concept 10 False negatives corrections: 0.14285714285714285 11 77\nInt concept 11 False negatives corrections: 0.06493506493506493 5 77\nFalse negatives corrections: 0.2597402597402597 20 77\nInt concept 0 False positives corrections: 0.6956521739130435 32 46\nInt concept 1 False positives corrections: 0.8695652173913043 40 46\nInt concept 2 False positives corrections: 0.9565217391304348 44 46\nInt concept 3 False positives corrections: 0.8478260869565217 39 46\nInt concept 4 False positives corrections: 0.8478260869565217 39 46\nInt concept 5 False positives corrections: 0.8260869565217391 38 46\nInt concept 6 False positives corrections: 0.8478260869565217 39 46\nInt concept 7 False positives corrections: 0.8695652173913043 40 46\nInt concept 8 False positives corrections: 0.9347826086956522 43 46\nInt concept 9 False positives corrections: 0.8695652173913043 40 46\nInt concept 10 False positives corrections: 0.7391304347826086 34 46\nInt concept 11 False positives corrections: 0.8913043478260869 41 46\nFalse positives corrections: 0.9565217391304348 44 46\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Interventions over enhanced CBM","metadata":{}},{"cell_type":"code","source":"class Int3(nn.Module):\n    def __init__(self, num_features, num_binary_concepts, num_continuous_concepts, num_llm_concepts, num_labels):\n        super(Int3, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_binary_concepts, bias=False)\n        self.layer2 = nn.Linear(num_features, num_continuous_concepts, bias=False)\n        self.layer3 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer4 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        self.layer5 = nn.Linear(num_llm_concepts, num_labels, bias=False)\n\n    def forward(self, x, binary_int, llm_c):\n        #binary_c = self.layer1(x)\n        continuous_c = self.layer2(x)\n        \n        #binary_c = torch.sigmoid(binary_c)\n        \n        y_pred = torch.sigmoid(self.layer3(binary_int)+self.layer4(continuous_c)+self.layer5(llm_c))\n        return y_pred\n\nclass Int4(nn.Module):\n    def __init__(self, num_features, num_binary_concepts, num_continuous_concepts, num_llm_concepts, num_labels):\n        super(Int4, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_binary_concepts, bias=False)\n        self.layer2 = nn.Linear(num_features, num_continuous_concepts, bias=False)\n        self.layer3 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer4 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        self.layer5 = nn.Linear(num_llm_concepts, num_labels, bias=False)\n\n    def forward(self, x, continuous_int, llm_c):\n        binary_c = self.layer1(x)\n        #continuous_c = self.layer2(x)\n        \n        binary_c = torch.sigmoid(binary_c)\n        \n        y_pred = torch.sigmoid(self.layer3(binary_c)+self.layer4(continuous_int)+self.layer5(llm_c))\n        return y_pred\n\nclass Int5(nn.Module):\n    def __init__(self, num_features, num_binary_concepts, num_continuous_concepts, num_llm_concepts, num_labels):\n        super(Int5, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_binary_concepts, bias=False)\n        self.layer2 = nn.Linear(num_features, num_continuous_concepts, bias=False)\n        self.layer3 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer4 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        self.layer5 = nn.Linear(num_llm_concepts, num_labels, bias=False)\n\n    def forward(self, x, llm_int):\n        binary_c = self.layer1(x)\n        continuous_c = self.layer2(x)\n        \n        binary_c = torch.sigmoid(binary_c)\n        \n        y_pred = torch.sigmoid(self.layer3(binary_c)+self.layer4(continuous_c)+self.layer5(llm_int))\n        return y_pred\n\nmodel_int3 = Int3(26,2,12,8,1)\nmodel_int4 = Int4(26,2,12,8,1)\nmodel_int5 = Int5(26,2,12,8,1)\n\nfor p1,p2 in zip(model_int3.parameters(),model2.parameters()):\n    p1.data = p2.data\n\nfor p1,p2 in zip(model_int4.parameters(),model2.parameters()):\n    p1.data = p2.data\n\nfor p1,p2 in zip(model_int5.parameters(),model2.parameters()):\n    p1.data = p2.data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:36.315577Z","iopub.execute_input":"2025-04-11T17:26:36.315861Z","iopub.status.idle":"2025-04-11T17:26:36.333758Z","shell.execute_reply.started":"2025-04-11T17:26:36.315837Z","shell.execute_reply":"2025-04-11T17:26:36.332450Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Binary concepts: Replacement with ground truth concept","metadata":{}},{"cell_type":"code","source":"#intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\nintervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = test_concepts[a][int_index]\n        b = b[-2:]\n        \n        with torch.no_grad():\n            p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[12] = test_concepts[a][12]\n    b[13] = test_concepts[a][13]\n    b = b[-2:]\n    \n    with torch.no_grad():\n        p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = test_concepts[a][int_index]\n        b = b[-2:]\n        \n        with torch.no_grad():\n            p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[12] = test_concepts[a][12]\n    b[13] = test_concepts[a][13]\n    \n    b = b[-2:]\n    \n    with torch.no_grad():\n        p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:36.334936Z","iopub.execute_input":"2025-04-11T17:26:36.335248Z","iopub.status.idle":"2025-04-11T17:26:36.417171Z","shell.execute_reply.started":"2025-04-11T17:26:36.335221Z","shell.execute_reply":"2025-04-11T17:26:36.416010Z"}},"outputs":[{"name":"stdout","text":"Int concept 12 False negatives corrections: 0.45454545454545453 10 22\nInt concept 13 False negatives corrections: 0.18181818181818182 4 22\nFalse negatives corrections: 0.18181818181818182 4 22\nInt concept 12 False positives corrections: 0.12727272727272726 7 55\nInt concept 13 False positives corrections: 0.10909090909090909 6 55\nFalse positives corrections: 0.09090909090909091 5 55\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"### Binary concepts: Replacement with mean","metadata":{}},{"cell_type":"code","source":"#intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\nintervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = np.mean(test_concepts,axis=0)[int_index]\n        b = b[-2:]\n        \n        with torch.no_grad():\n            p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    b[13] = np.mean(test_concepts,axis=0)[13]\n    b = b[-2:]\n    \n    with torch.no_grad():\n        p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = np.mean(test_concepts,axis=0)[int_index]\n        b = b[-2:]\n        \n        with torch.no_grad():\n            p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    b[13] = np.mean(test_concepts,axis=0)[13]\n    \n    b = b[-2:]\n    \n    with torch.no_grad():\n        p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:36.418312Z","iopub.execute_input":"2025-04-11T17:26:36.418642Z","iopub.status.idle":"2025-04-11T17:26:36.500935Z","shell.execute_reply.started":"2025-04-11T17:26:36.418613Z","shell.execute_reply":"2025-04-11T17:26:36.499922Z"}},"outputs":[{"name":"stdout","text":"Int concept 12 False negatives corrections: 0.4090909090909091 9 22\nInt concept 13 False negatives corrections: 0.22727272727272727 5 22\nFalse negatives corrections: 0.3181818181818182 7 22\nInt concept 12 False positives corrections: 0.07272727272727272 4 55\nInt concept 13 False positives corrections: 0.16363636363636364 9 55\nFalse positives corrections: 0.12727272727272726 7 55\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"### Binary concepts: Replacement with median","metadata":{}},{"cell_type":"code","source":"#intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\nintervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = np.median(test_concepts,axis=0)[int_index]\n        b = b[-2:]\n        \n        with torch.no_grad():\n            p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[12] = np.median(test_concepts,axis=0)[12]\n    b[13] = np.median(test_concepts,axis=0)[13]\n    b = b[-2:]\n    \n    with torch.no_grad():\n        p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = np.median(test_concepts,axis=0)[int_index]\n        b = b[-2:]\n        \n        with torch.no_grad():\n            p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[12] = np.median(test_concepts,axis=0)[12]\n    b[13] = np.median(test_concepts,axis=0)[13]\n    \n    b = b[-2:]\n    \n    with torch.no_grad():\n        p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:36.501893Z","iopub.execute_input":"2025-04-11T17:26:36.502227Z","iopub.status.idle":"2025-04-11T17:26:36.634737Z","shell.execute_reply.started":"2025-04-11T17:26:36.502200Z","shell.execute_reply":"2025-04-11T17:26:36.633520Z"}},"outputs":[{"name":"stdout","text":"Int concept 12 False negatives corrections: 0.45454545454545453 10 22\nInt concept 13 False negatives corrections: 0.0 0 22\nFalse negatives corrections: 0.0 0 22\nInt concept 12 False positives corrections: 0.05454545454545454 3 55\nInt concept 13 False positives corrections: 0.2909090909090909 16 55\nFalse positives corrections: 0.23636363636363636 13 55\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Continuous concepts: Replacement with ground truth concept","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n#intervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = test_concepts[a][int_index]\n        b = b[:-2]\n        \n        with torch.no_grad():\n            p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_negatives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    #b[3] = test_concepts[a][3]\n    #b[0] = test_concepts[a][0]\n    #b[1] = test_concepts[a][1]\n    \n    b[7] = test_concepts[a][7]\n    b = b[:-2]\n    \n    with torch.no_grad():\n        p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = test_concepts[a][int_index]\n        b = b[:-2]\n        \n        with torch.no_grad():\n            p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[5] = test_concepts[a][5]\n    b[6] = test_concepts[a][6]\n    b[9] = test_concepts[a][9]\n    \n    b = b[:-2]\n    \n    with torch.no_grad():\n        p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:36.636047Z","iopub.execute_input":"2025-04-11T17:26:36.636378Z","iopub.status.idle":"2025-04-11T17:26:36.866512Z","shell.execute_reply.started":"2025-04-11T17:26:36.636350Z","shell.execute_reply":"2025-04-11T17:26:36.865430Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.09090909090909091 2 22\nInt concept 1 False negatives corrections: 0.09090909090909091 2 22\nInt concept 2 False negatives corrections: 0.09090909090909091 2 22\nInt concept 3 False negatives corrections: 0.09090909090909091 2 22\nInt concept 4 False negatives corrections: 0.09090909090909091 2 22\nInt concept 5 False negatives corrections: 0.045454545454545456 1 22\nInt concept 6 False negatives corrections: 0.09090909090909091 2 22\nInt concept 7 False negatives corrections: 0.13636363636363635 3 22\nInt concept 8 False negatives corrections: 0.09090909090909091 2 22\nInt concept 9 False negatives corrections: 0.045454545454545456 1 22\nInt concept 10 False negatives corrections: 0.09090909090909091 2 22\nInt concept 11 False negatives corrections: 0.09090909090909091 2 22\nFalse negatives corrections: 0.13636363636363635 3 22\nInt concept 0 False positives corrections: 0.05454545454545454 3 55\nInt concept 1 False positives corrections: 0.05454545454545454 3 55\nInt concept 2 False positives corrections: 0.05454545454545454 3 55\nInt concept 3 False positives corrections: 0.05454545454545454 3 55\nInt concept 4 False positives corrections: 0.05454545454545454 3 55\nInt concept 5 False positives corrections: 0.07272727272727272 4 55\nInt concept 6 False positives corrections: 0.07272727272727272 4 55\nInt concept 7 False positives corrections: 0.03636363636363636 2 55\nInt concept 8 False positives corrections: 0.05454545454545454 3 55\nInt concept 9 False positives corrections: 0.07272727272727272 4 55\nInt concept 10 False positives corrections: 0.05454545454545454 3 55\nInt concept 11 False positives corrections: 0.05454545454545454 3 55\nFalse positives corrections: 0.09090909090909091 5 55\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"### Continuous concepts: Replacement with mean","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n#intervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = np.mean(test_concepts,axis=0)[int_index]\n        b = b[:-2]\n        \n        with torch.no_grad():\n            p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_negatives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[3] = np.mean(test_concepts,axis=0)[3]\n    b[6] = np.mean(test_concepts,axis=0)[6]\n    #b[10] = test_concepts[a][10]\n    b = b[:-2]\n    \n    with torch.no_grad():\n        p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = np.mean(test_concepts,axis=0)[int_index]\n        b = b[:-2]\n        \n        with torch.no_grad():\n            p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[2] = np.mean(test_concepts,axis=0)[2]\n    b[4] = np.mean(test_concepts,axis=0)[4]\n    b[5] = np.mean(test_concepts,axis=0)[5]\n    b[8] = np.mean(test_concepts,axis=0)[8]\n    #b[11] = np.mean(test_concepts,axis=0)[11]\n    \n    b = b[:-2]\n    \n    with torch.no_grad():\n        p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:36.867620Z","iopub.execute_input":"2025-04-11T17:26:36.867930Z","iopub.status.idle":"2025-04-11T17:26:37.164702Z","shell.execute_reply.started":"2025-04-11T17:26:36.867893Z","shell.execute_reply":"2025-04-11T17:26:37.163469Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.09090909090909091 2 22\nInt concept 1 False negatives corrections: 0.09090909090909091 2 22\nInt concept 2 False negatives corrections: 0.09090909090909091 2 22\nInt concept 3 False negatives corrections: 0.09090909090909091 2 22\nInt concept 4 False negatives corrections: 0.09090909090909091 2 22\nInt concept 5 False negatives corrections: 0.045454545454545456 1 22\nInt concept 6 False negatives corrections: 0.13636363636363635 3 22\nInt concept 7 False negatives corrections: 0.09090909090909091 2 22\nInt concept 8 False negatives corrections: 0.09090909090909091 2 22\nInt concept 9 False negatives corrections: 0.09090909090909091 2 22\nInt concept 10 False negatives corrections: 0.09090909090909091 2 22\nInt concept 11 False negatives corrections: 0.09090909090909091 2 22\nFalse negatives corrections: 0.13636363636363635 3 22\nInt concept 0 False positives corrections: 0.05454545454545454 3 55\nInt concept 1 False positives corrections: 0.05454545454545454 3 55\nInt concept 2 False positives corrections: 0.05454545454545454 3 55\nInt concept 3 False positives corrections: 0.05454545454545454 3 55\nInt concept 4 False positives corrections: 0.05454545454545454 3 55\nInt concept 5 False positives corrections: 0.07272727272727272 4 55\nInt concept 6 False positives corrections: 0.05454545454545454 3 55\nInt concept 7 False positives corrections: 0.05454545454545454 3 55\nInt concept 8 False positives corrections: 0.03636363636363636 2 55\nInt concept 9 False positives corrections: 0.07272727272727272 4 55\nInt concept 10 False positives corrections: 0.05454545454545454 3 55\nInt concept 11 False positives corrections: 0.05454545454545454 3 55\nFalse positives corrections: 0.05454545454545454 3 55\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"### Continuous concepts: Replacement with median","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n#intervention_concept_idxs = [12,13]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = np.median(test_concepts,axis=0)[int_index]\n        b = b[:-2]\n        \n        with torch.no_grad():\n            p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_negatives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[3] = np.median(test_concepts,axis=0)[3]\n    b[6] = np.median(test_concepts,axis=0)[6]\n    #b[10] = test_concepts[a][10]\n    b = b[:-2]\n    \n    with torch.no_grad():\n        p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = c_pred_llm[a].copy()\n\n        b[int_index] = np.median(test_concepts,axis=0)[int_index]\n        b = b[:-2]\n        \n        with torch.no_grad():\n            p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[2] = np.median(test_concepts,axis=0)[2]\n    b[4] = np.median(test_concepts,axis=0)[4]\n    b[5] = np.median(test_concepts,axis=0)[5]\n    b[8] = np.median(test_concepts,axis=0)[8]\n    #b[11] = np.mean(test_concepts,axis=0)[11]\n    \n    b = b[:-2]\n    \n    with torch.no_grad():\n        p_int = model_int4(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:37.165925Z","iopub.execute_input":"2025-04-11T17:26:37.166470Z","iopub.status.idle":"2025-04-11T17:26:37.683941Z","shell.execute_reply.started":"2025-04-11T17:26:37.166428Z","shell.execute_reply":"2025-04-11T17:26:37.682655Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.09090909090909091 2 22\nInt concept 1 False negatives corrections: 0.09090909090909091 2 22\nInt concept 2 False negatives corrections: 0.09090909090909091 2 22\nInt concept 3 False negatives corrections: 0.09090909090909091 2 22\nInt concept 4 False negatives corrections: 0.09090909090909091 2 22\nInt concept 5 False negatives corrections: 0.045454545454545456 1 22\nInt concept 6 False negatives corrections: 0.13636363636363635 3 22\nInt concept 7 False negatives corrections: 0.13636363636363635 3 22\nInt concept 8 False negatives corrections: 0.09090909090909091 2 22\nInt concept 9 False negatives corrections: 0.09090909090909091 2 22\nInt concept 10 False negatives corrections: 0.09090909090909091 2 22\nInt concept 11 False negatives corrections: 0.09090909090909091 2 22\nFalse negatives corrections: 0.13636363636363635 3 22\nInt concept 0 False positives corrections: 0.05454545454545454 3 55\nInt concept 1 False positives corrections: 0.05454545454545454 3 55\nInt concept 2 False positives corrections: 0.05454545454545454 3 55\nInt concept 3 False positives corrections: 0.05454545454545454 3 55\nInt concept 4 False positives corrections: 0.05454545454545454 3 55\nInt concept 5 False positives corrections: 0.07272727272727272 4 55\nInt concept 6 False positives corrections: 0.03636363636363636 2 55\nInt concept 7 False positives corrections: 0.03636363636363636 2 55\nInt concept 8 False positives corrections: 0.03636363636363636 2 55\nInt concept 9 False positives corrections: 0.05454545454545454 3 55\nInt concept 10 False positives corrections: 0.05454545454545454 3 55\nInt concept 11 False positives corrections: 0.05454545454545454 3 55\nFalse positives corrections: 0.05454545454545454 3 55\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_llm_concepts[false_negatives_idx_llm]\nnp.mean(test_llm_concepts[false_negatives_idx_llm],axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:37.685112Z","iopub.execute_input":"2025-04-11T17:26:37.685453Z","iopub.status.idle":"2025-04-11T17:26:37.694936Z","shell.execute_reply.started":"2025-04-11T17:26:37.685415Z","shell.execute_reply":"2025-04-11T17:26:37.693761Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array([0.27272728, 0.22727273, 0.8636364 , 0.3181818 , 0.72727275,\n       0.13636364, 0.4090909 , 0.04545455], dtype=float32)"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"test_llm_concepts[false_positives_idx_llm]\nnp.mean(test_llm_concepts[false_positives_idx_llm],axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:37.695947Z","iopub.execute_input":"2025-04-11T17:26:37.696258Z","iopub.status.idle":"2025-04-11T17:26:37.716923Z","shell.execute_reply.started":"2025-04-11T17:26:37.696230Z","shell.execute_reply":"2025-04-11T17:26:37.715715Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"array([0.6545454 , 0.38181818, 0.8909091 , 0.3272727 , 0.6363636 ,\n       0.03636364, 0.90909094, 0.        ], dtype=float32)"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Interventions over LLM concepts: Manual changes","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = test_llm_concepts[a].copy()\n\n        b[int_index] = 1.0\n        \n        with torch.no_grad():\n            p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_negatives_idx_llm:\n    b = test_llm_concepts[a].copy()\n\n    b[0] = 1.0\n    b[1] = 1.0\n    b[5] = 1.0\n    #b[6] = 1.0\n\n    if a==220:\n        print(p_int)\n        \n    with torch.no_grad():\n        p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nintervention_concept_idxs = [0,1,2,3,4,5,6,7]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = test_llm_concepts[a].copy()\n\n        b[int_index] = 0.0\n        \n        with torch.no_grad():\n            p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n    b = test_llm_concepts[a].copy()\n\n    b[0] = 0.0\n    b[2] = 0.0\n    b[6] = 0.0\n    \n    with torch.no_grad():\n        p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n\n    if a==23:\n        print(p_int)\n    \n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:37.718015Z","iopub.execute_input":"2025-04-11T17:26:37.718533Z","iopub.status.idle":"2025-04-11T17:26:37.893739Z","shell.execute_reply.started":"2025-04-11T17:26:37.718468Z","shell.execute_reply":"2025-04-11T17:26:37.892694Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.45454545454545453 10 22\nInt concept 1 False negatives corrections: 0.4090909090909091 9 22\nInt concept 2 False negatives corrections: 0.09090909090909091 2 22\nInt concept 3 False negatives corrections: 0.0 0 22\nInt concept 4 False negatives corrections: 0.0 0 22\nInt concept 5 False negatives corrections: 0.5454545454545454 12 22\nInt concept 6 False negatives corrections: 0.4090909090909091 9 22\nInt concept 7 False negatives corrections: 0.0 0 22\ntensor([[0.9617]])\nFalse negatives corrections: 0.9545454545454546 21 22\nInt concept 0 False positives corrections: 0.4 22 55\nInt concept 1 False positives corrections: 0.12727272727272726 7 55\nInt concept 2 False positives corrections: 0.34545454545454546 19 55\nInt concept 3 False positives corrections: 0.0 0 55\nInt concept 4 False positives corrections: 0.0 0 55\nInt concept 5 False positives corrections: 0.0 0 55\nInt concept 6 False positives corrections: 0.7636363636363637 42 55\nInt concept 7 False positives corrections: 0.0 0 55\ntensor([[0.0516]])\nFalse positives corrections: 1.0 55 55\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"false_positives_idx_llm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:37.894574Z","iopub.execute_input":"2025-04-11T17:26:37.894849Z","iopub.status.idle":"2025-04-11T17:26:37.900812Z","shell.execute_reply.started":"2025-04-11T17:26:37.894823Z","shell.execute_reply":"2025-04-11T17:26:37.899669Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"array([  7,  22,  23,  25,  33,  42,  54,  60,  65,  69,  79,  82,  83,\n        91,  95,  98, 100, 101, 104, 111, 134, 136, 141, 144, 168, 171,\n       177, 178, 181, 184, 186, 201, 206, 209, 214, 217, 218, 222, 223,\n       245, 248, 254, 270, 288, 315, 318, 327, 328, 333, 350, 361, 368,\n       372, 378, 388])"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Interventions over LLM concepts: Replacements with Mean","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = test_llm_concepts[a].copy()\n\n        b[int_index] = np.mean(test_llm_concepts,axis=0)[int_index]\n        \n        with torch.no_grad():\n            p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_negatives_idx_llm:\n    b = test_llm_concepts[a].copy()\n\n    b[0] = np.mean(test_llm_concepts,axis=0)[0]\n    b[6] = np.mean(test_llm_concepts,axis=0)[6]\n    \n    with torch.no_grad():\n        p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nintervention_concept_idxs = [0,1,2,3,4,5,6,7]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = test_llm_concepts[a].copy()\n\n        b[int_index] = np.mean(test_llm_concepts,axis=0)[int_index]\n        \n        with torch.no_grad():\n            p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n    b = test_llm_concepts[a].copy()\n\n    b[0] = np.mean(test_llm_concepts,axis=0)[0]\n    b[1] = np.mean(test_llm_concepts,axis=0)[1]\n    b[6] = np.mean(test_llm_concepts,axis=0)[6]\n    \n    with torch.no_grad():\n        p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:37.902042Z","iopub.execute_input":"2025-04-11T17:26:37.902435Z","iopub.status.idle":"2025-04-11T17:26:38.118020Z","shell.execute_reply.started":"2025-04-11T17:26:37.902388Z","shell.execute_reply":"2025-04-11T17:26:38.116885Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.3181818181818182 7 22\nInt concept 1 False negatives corrections: 0.18181818181818182 4 22\nInt concept 2 False negatives corrections: 0.09090909090909091 2 22\nInt concept 3 False negatives corrections: 0.09090909090909091 2 22\nInt concept 4 False negatives corrections: 0.22727272727272727 5 22\nInt concept 5 False negatives corrections: 0.13636363636363635 3 22\nInt concept 6 False negatives corrections: 0.2727272727272727 6 22\nInt concept 7 False negatives corrections: 0.0 0 22\nFalse negatives corrections: 0.5454545454545454 12 22\nInt concept 0 False positives corrections: 0.09090909090909091 5 55\nInt concept 1 False positives corrections: 0.09090909090909091 5 55\nInt concept 2 False positives corrections: 0.01818181818181818 1 55\nInt concept 3 False positives corrections: 0.0 0 55\nInt concept 4 False positives corrections: 0.03636363636363636 2 55\nInt concept 5 False positives corrections: 0.0 0 55\nInt concept 6 False positives corrections: 0.14545454545454545 8 55\nInt concept 7 False positives corrections: 0.0 0 55\nFalse positives corrections: 0.2 11 55\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"### Interventions over LLM concepts: Replacements with Median","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_negatives_idx_llm:\n        b = test_llm_concepts[a].copy()\n\n        b[int_index] = np.median(test_llm_concepts,axis=0)[int_index]\n        \n        with torch.no_grad():\n            p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_negatives_idx_llm:\n    b = test_llm_concepts[a].copy()\n\n    b[0] = np.median(test_llm_concepts,axis=0)[0]\n    b[6] = np.median(test_llm_concepts,axis=0)[6]\n    \n    with torch.no_grad():\n        p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\nintervention_concept_idxs = [0,1,2,3,4,5,6,7]\n\nfor int_index in intervention_concept_idxs:\n    \n    count = 0\n    total = 0\n    for a in false_positives_idx_llm:\n        b = test_llm_concepts[a].copy()\n\n        b[int_index] = np.median(test_llm_concepts,axis=0)[int_index]\n        \n        with torch.no_grad():\n            p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",int_index,\"False positives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n    b = test_llm_concepts[a].copy()\n\n    b[1] = np.median(test_llm_concepts,axis=0)[1]\n    b[4] = np.median(test_llm_concepts,axis=0)[4]\n    \n    with torch.no_grad():\n        p_int = model_int5(torch.tensor(test_features[a:a+1]),torch.tensor([b]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:38.118988Z","iopub.execute_input":"2025-04-11T17:26:38.119282Z","iopub.status.idle":"2025-04-11T17:26:38.409205Z","shell.execute_reply.started":"2025-04-11T17:26:38.119246Z","shell.execute_reply":"2025-04-11T17:26:38.407993Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.45454545454545453 10 22\nInt concept 1 False negatives corrections: 0.0 0 22\nInt concept 2 False negatives corrections: 0.09090909090909091 2 22\nInt concept 3 False negatives corrections: 0.09090909090909091 2 22\nInt concept 4 False negatives corrections: 0.0 0 22\nInt concept 5 False negatives corrections: 0.0 0 22\nInt concept 6 False negatives corrections: 0.4090909090909091 9 22\nInt concept 7 False negatives corrections: 0.0 0 22\nFalse negatives corrections: 0.9090909090909091 20 22\nInt concept 0 False positives corrections: 0.0 0 55\nInt concept 1 False positives corrections: 0.12727272727272726 7 55\nInt concept 2 False positives corrections: 0.0 0 55\nInt concept 3 False positives corrections: 0.0 0 55\nInt concept 4 False positives corrections: 0.10909090909090909 6 55\nInt concept 5 False positives corrections: 0.0 0 55\nInt concept 6 False positives corrections: 0.0 0 55\nInt concept 7 False positives corrections: 0.0 0 55\nFalse positives corrections: 0.23636363636363636 13 55\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Interventions: Corrections over all three kinds of concepts simultaneously.","metadata":{}},{"cell_type":"code","source":"class Int6(nn.Module):\n    def __init__(self, num_features, num_binary_concepts, num_continuous_concepts, num_llm_concepts, num_labels):\n        super(Int6, self).__init__()\n        \n        self.layer1 = nn.Linear(num_features, num_binary_concepts, bias=False)\n        self.layer2 = nn.Linear(num_features, num_continuous_concepts, bias=False)\n        self.layer3 = nn.Linear(num_binary_concepts, num_labels, bias=False)\n        self.layer4 = nn.Linear(num_continuous_concepts, num_labels, bias=False)\n        self.layer5 = nn.Linear(num_llm_concepts, num_labels, bias=False)\n\n    def forward(self, x, binary_int, continuous_int, llm_int):\n        #binary_c = self.layer1(x)\n        #continuous_c = self.layer2(x)\n        \n        #binary_c = torch.sigmoid(binary_c)\n        \n        y_pred = torch.sigmoid(self.layer3(binary_int)+self.layer4(continuous_int)+self.layer5(llm_int))\n        return y_pred\n\nmodel_int6 = Int6(26,2,12,8,1)\n\nfor p1,p2 in zip(model_int6.parameters(),model2.parameters()):\n    p1.data = p2.data","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:38.410189Z","iopub.execute_input":"2025-04-11T17:26:38.410578Z","iopub.status.idle":"2025-04-11T17:26:38.419441Z","shell.execute_reply.started":"2025-04-11T17:26:38.410549Z","shell.execute_reply":"2025-04-11T17:26:38.418242Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"### Best of ground truth replacements","metadata":{}},{"cell_type":"code","source":"count = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n\n    b = c_pred_llm[a].copy()\n    b[12] = test_concepts[a][12]\n    b = b[-2:]\n    \n    c = c_pred_llm[a].copy()\n    c[7] = test_concepts[a][7]\n    c = c[:-2]\n    \n    d = test_llm_concepts[a].copy()\n    d[0] = 1.0 \n    d[1] = 1.0\n    d[5] = 1.0\n\n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b]),torch.tensor([c]),torch.tensor([d]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count, total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n\n    b = c_pred_llm[a].copy()\n    b[12] = test_concepts[a][12]\n    b = b[-2:]\n    \n    c = c_pred_llm[a].copy()\n    c[5] = test_concepts[a][5]\n    c[6] = test_concepts[a][6]\n    c[9] = test_concepts[a][9]\n    c = c[:-2]\n    \n    d = test_llm_concepts[a].copy()\n    d[0] = 0.0 \n    d[2] = 0.0\n    d[6] = 0.0\n    \n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b]),torch.tensor([c]),torch.tensor([d]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:38.420627Z","iopub.execute_input":"2025-04-11T17:26:38.420966Z","iopub.status.idle":"2025-04-11T17:26:38.470468Z","shell.execute_reply.started":"2025-04-11T17:26:38.420935Z","shell.execute_reply":"2025-04-11T17:26:38.469233Z"}},"outputs":[{"name":"stdout","text":"False negatives corrections: 1.0 22 22\nFalse positives corrections: 1.0 55 55\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"### Best of mean replacements","metadata":{}},{"cell_type":"code","source":"count = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n\n    b = c_pred_llm[a].copy()\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    b = b[-2:]\n    \n    c = c_pred_llm[a].copy()\n    c[7] = np.mean(test_concepts,axis=0)[7]\n    c = c[:-2]\n    \n    d = test_llm_concepts[a].copy()\n    d[0] = np.mean(test_llm_concepts,axis=0)[0]\n    d[6] = np.mean(test_llm_concepts,axis=0)[6]\n    \n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b]),torch.tensor([c]),torch.tensor([d]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count, total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n\n    b = c_pred_llm[a].copy()\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    b = b[-2:]\n    \n    c = c_pred_llm[a].copy()\n    c[5] = np.mean(test_concepts,axis=0)[5]\n    c[6] = np.mean(test_concepts,axis=0)[6]\n    c[9] = np.mean(test_concepts,axis=0)[9]\n    c = c[:-2]\n    \n    d = test_llm_concepts[a].copy()\n    d[0] = np.mean(test_llm_concepts,axis=0)[0]\n    d[1] = np.mean(test_llm_concepts,axis=0)[1]\n    d[6] = np.mean(test_llm_concepts,axis=0)[6]\n    \n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b]),torch.tensor([c]),torch.tensor([d]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:38.471629Z","iopub.execute_input":"2025-04-11T17:26:38.472200Z","iopub.status.idle":"2025-04-11T17:26:38.521141Z","shell.execute_reply.started":"2025-04-11T17:26:38.471954Z","shell.execute_reply":"2025-04-11T17:26:38.520086Z"}},"outputs":[{"name":"stdout","text":"False negatives corrections: 0.7727272727272727 17 22\nFalse positives corrections: 0.18181818181818182 10 55\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"### Best of Median Replacements","metadata":{}},{"cell_type":"code","source":"count = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n\n    b = c_pred_llm[a].copy()\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    b = b[-2:]\n    \n    c = c_pred_llm[a].copy()\n    c[7] = np.mean(test_concepts,axis=0)[7]\n    c = c[:-2]\n    \n    d = test_llm_concepts[a].copy()\n    d[0] = np.mean(test_llm_concepts,axis=0)[0]\n    d[6] = np.mean(test_llm_concepts,axis=0)[6]\n    \n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b]),torch.tensor([c]),torch.tensor([d]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count, total)\n\ncount = 0\ntotal = 0\nfor a in false_positives_idx_llm:\n\n    b = c_pred_llm[a].copy()\n    b[12] = np.median(test_concepts,axis=0)[12]\n    b = b[-2:]\n    \n    c = c_pred_llm[a].copy()\n    c[5] = np.median(test_concepts,axis=0)[5]\n    c[6] = np.median(test_concepts,axis=0)[6]\n    c[9] = np.median(test_concepts,axis=0)[9]\n    c = c[:-2]\n    \n    d = test_llm_concepts[a].copy()\n    d[1] = np.median(test_llm_concepts,axis=0)[1]\n    d[4] = np.median(test_llm_concepts,axis=0)[4]\n    \n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b]),torch.tensor([c]),torch.tensor([d]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-11T17:26:38.522104Z","iopub.execute_input":"2025-04-11T17:26:38.522396Z","iopub.status.idle":"2025-04-11T17:26:38.601763Z","shell.execute_reply.started":"2025-04-11T17:26:38.522371Z","shell.execute_reply":"2025-04-11T17:26:38.600762Z"}},"outputs":[{"name":"stdout","text":"False negatives corrections: 0.7727272727272727 17 22\nFalse positives corrections: 0.18181818181818182 10 55\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Correlated Concepts","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nimport numpy as np  # ensure this is imported if not already\n\nnames2 = list(C_cont.columns) + list(C_bin.columns) + list(LLM_C.columns)\nnames = [name[2:] if i <= 13 else name for i, name in enumerate(names2)]\n\nfig, ax = plt.subplots(figsize=(5, 5))\nall_concepts = np.concatenate([test_concepts, test_llm_concepts], axis=1)\ncorr = np.corrcoef(all_concepts, rowvar=False)\n\nim = ax.imshow(corr, cmap='coolwarm')\n\n# Create an axis on the right of ax for the colorbar\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\nplt.colorbar(im, cax=cax)\n\nax.set_title(\"Correlation Matrix\", fontsize=12)\nax.set_xticks(np.arange(len(names)))\nax.set_xticklabels(names, rotation=90, fontsize=6, fontweight='medium')\nax.set_yticks(np.arange(len(names)))\nax.set_yticklabels(names, fontsize=6, fontweight='medium')\n\n# Improve tick visibility\nax.tick_params(axis='both', which='major', length=2.5, width=0.5)\n\n# Tight layout and remove whitespace when saving\nplt.tight_layout()\nplt.savefig(\"correlations.png\", dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:30:00.635704Z","iopub.execute_input":"2025-04-11T17:30:00.636142Z","iopub.status.idle":"2025-04-11T17:30:01.850574Z","shell.execute_reply.started":"2025-04-11T17:30:00.636109Z","shell.execute_reply":"2025-04-11T17:30:01.849067Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 500x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":102},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Correlated corrections over enhanced CBMs: Main intervention on vanilla using GT, translate to all, including LLM concepts","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_negatives_idx_llm:\n\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = test_concepts[a][change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        d = test_llm_concepts[a].copy()\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n    \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------------\")\nintervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_positives_idx_llm:\n\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = test_concepts[a][change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] - corr[change,val]*delta\n        \n        d = test_llm_concepts[a].copy()\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] - corr[change,val]*delta\n    \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:39.884501Z","iopub.execute_input":"2025-04-11T17:26:39.884895Z","iopub.status.idle":"2025-04-11T17:26:40.156189Z","shell.execute_reply.started":"2025-04-11T17:26:39.884862Z","shell.execute_reply":"2025-04-11T17:26:40.154877Z"}},"outputs":[{"name":"stdout","text":"Intervention index 0 False negatives corrections: 0.36363636363636365 8 22\nIntervention index 1 False negatives corrections: 0.45454545454545453 10 22\nIntervention index 2 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 3 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 4 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 5 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 6 False negatives corrections: 0.3181818181818182 7 22\nIntervention index 7 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 8 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 9 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 10 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 11 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 12 False negatives corrections: 0.7272727272727273 16 22\nIntervention index 13 False negatives corrections: 0.18181818181818182 4 22\n----------------------\nIntervention index 0 False positives corrections: 0.14545454545454545 8 55\nIntervention index 1 False positives corrections: 0.18181818181818182 10 55\nIntervention index 2 False positives corrections: 0.18181818181818182 10 55\nIntervention index 3 False positives corrections: 0.16363636363636364 9 55\nIntervention index 4 False positives corrections: 0.14545454545454545 8 55\nIntervention index 5 False positives corrections: 0.14545454545454545 8 55\nIntervention index 6 False positives corrections: 0.07272727272727272 4 55\nIntervention index 7 False positives corrections: 0.16363636363636364 9 55\nIntervention index 8 False positives corrections: 0.16363636363636364 9 55\nIntervention index 9 False positives corrections: 0.16363636363636364 9 55\nIntervention index 10 False positives corrections: 0.10909090909090909 6 55\nIntervention index 11 False positives corrections: 0.16363636363636364 9 55\nIntervention index 12 False positives corrections: 0.4 22 55\nIntervention index 13 False positives corrections: 0.2909090909090909 16 55\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"## Correlated corrections over enhanced CBMs: Main intervention on vanilla using mean, translate to all, including LLM concepts","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_negatives_idx_llm:\n\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = np.mean(test_concepts,axis=0)[change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        d = test_llm_concepts[a].copy()\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n    \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------------\")\nintervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_positives_idx_llm:\n\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = np.mean(test_concepts,axis=0)[change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] - corr[change,val]*delta\n        \n        d = test_llm_concepts[a].copy()\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] - corr[change,val]*delta\n    \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:40.158693Z","iopub.execute_input":"2025-04-11T17:26:40.159020Z","iopub.status.idle":"2025-04-11T17:26:40.499091Z","shell.execute_reply.started":"2025-04-11T17:26:40.158990Z","shell.execute_reply":"2025-04-11T17:26:40.498046Z"}},"outputs":[{"name":"stdout","text":"Intervention index 0 False negatives corrections: 0.3181818181818182 7 22\nIntervention index 1 False negatives corrections: 0.45454545454545453 10 22\nIntervention index 2 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 3 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 4 False negatives corrections: 0.36363636363636365 8 22\nIntervention index 5 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 6 False negatives corrections: 0.45454545454545453 10 22\nIntervention index 7 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 8 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 9 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 10 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 11 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 12 False negatives corrections: 0.5 11 22\nIntervention index 13 False negatives corrections: 0.045454545454545456 1 22\n----------------------\nIntervention index 0 False positives corrections: 0.16363636363636364 9 55\nIntervention index 1 False positives corrections: 0.18181818181818182 10 55\nIntervention index 2 False positives corrections: 0.16363636363636364 9 55\nIntervention index 3 False positives corrections: 0.16363636363636364 9 55\nIntervention index 4 False positives corrections: 0.18181818181818182 10 55\nIntervention index 5 False positives corrections: 0.12727272727272726 7 55\nIntervention index 6 False positives corrections: 0.09090909090909091 5 55\nIntervention index 7 False positives corrections: 0.14545454545454545 8 55\nIntervention index 8 False positives corrections: 0.16363636363636364 9 55\nIntervention index 9 False positives corrections: 0.12727272727272726 7 55\nIntervention index 10 False positives corrections: 0.09090909090909091 5 55\nIntervention index 11 False positives corrections: 0.16363636363636364 9 55\nIntervention index 12 False positives corrections: 0.34545454545454546 19 55\nIntervention index 13 False positives corrections: 0.16363636363636364 9 55\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"## Correlated corrections over enhanced CBMs: Main intervention on vanilla using median, translate to all, including LLM concepts","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_negatives_idx_llm:\n\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = np.median(test_concepts,axis=0)[change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        d = test_llm_concepts[a].copy()\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n    \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------------\")\nintervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_positives_idx_llm:\n\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = np.median(test_concepts,axis=0)[change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] - corr[change,val]*delta\n        \n        d = test_llm_concepts[a].copy()\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] - corr[change,val]*delta\n    \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:40.500122Z","iopub.execute_input":"2025-04-11T17:26:40.500517Z","iopub.status.idle":"2025-04-11T17:26:41.009001Z","shell.execute_reply.started":"2025-04-11T17:26:40.500453Z","shell.execute_reply":"2025-04-11T17:26:41.007965Z"}},"outputs":[{"name":"stdout","text":"Intervention index 0 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 1 False negatives corrections: 0.45454545454545453 10 22\nIntervention index 2 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 3 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 4 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 5 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 6 False negatives corrections: 0.45454545454545453 10 22\nIntervention index 7 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 8 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 9 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 10 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 11 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 12 False negatives corrections: 0.8181818181818182 18 22\nIntervention index 13 False negatives corrections: 0.0 0 22\n----------------------\nIntervention index 0 False positives corrections: 0.16363636363636364 9 55\nIntervention index 1 False positives corrections: 0.18181818181818182 10 55\nIntervention index 2 False positives corrections: 0.14545454545454545 8 55\nIntervention index 3 False positives corrections: 0.16363636363636364 9 55\nIntervention index 4 False positives corrections: 0.12727272727272726 7 55\nIntervention index 5 False positives corrections: 0.12727272727272726 7 55\nIntervention index 6 False positives corrections: 0.09090909090909091 5 55\nIntervention index 7 False positives corrections: 0.14545454545454545 8 55\nIntervention index 8 False positives corrections: 0.14545454545454545 8 55\nIntervention index 9 False positives corrections: 0.16363636363636364 9 55\nIntervention index 10 False positives corrections: 0.09090909090909091 5 55\nIntervention index 11 False positives corrections: 0.16363636363636364 9 55\nIntervention index 12 False positives corrections: 0.5454545454545454 30 55\nIntervention index 13 False positives corrections: 0.4727272727272727 26 55\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Correlated corrections over enhanced CBMs using ground truth: Main intervention on LLM, translate to all","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [14,15,16,17,18,19,20,21]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_negatives_idx_llm:\n\n        d = test_llm_concepts[a].copy()\n        orig_value = d[change-14] \n        d[change-14] = 1.0\n        delta = orig_value-d[change-14]\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n\n        b = c_pred[a].copy()\n    \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------\")\nintervention_concept_idxs = [14,15,16,17,18,19,20,21]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_positives_idx_llm:\n\n        d = test_llm_concepts[a].copy()\n        orig_value = d[change-14] \n        d[change-14] = 0.0\n        delta = orig_value-d[change-14]\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n\n        b = c_pred[a].copy()\n    \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:41.009937Z","iopub.execute_input":"2025-04-11T17:26:41.010243Z","iopub.status.idle":"2025-04-11T17:26:41.170618Z","shell.execute_reply.started":"2025-04-11T17:26:41.010216Z","shell.execute_reply":"2025-04-11T17:26:41.169567Z"}},"outputs":[{"name":"stdout","text":"Intervention index 14 False negatives corrections: 0.3181818181818182 7 22\nIntervention index 15 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 16 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 17 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 18 False negatives corrections: 0.13636363636363635 3 22\nIntervention index 19 False negatives corrections: 0.45454545454545453 10 22\nIntervention index 20 False negatives corrections: 0.36363636363636365 8 22\nIntervention index 21 False negatives corrections: 0.045454545454545456 1 22\n----------------\nIntervention index 14 False positives corrections: 0.2 11 55\nIntervention index 15 False positives corrections: 0.16363636363636364 9 55\nIntervention index 16 False positives corrections: 0.3090909090909091 17 55\nIntervention index 17 False positives corrections: 0.16363636363636364 9 55\nIntervention index 18 False positives corrections: 0.09090909090909091 5 55\nIntervention index 19 False positives corrections: 0.18181818181818182 10 55\nIntervention index 20 False positives corrections: 0.38181818181818183 21 55\nIntervention index 21 False positives corrections: 0.16363636363636364 9 55\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"## Correlated corrections over enhanced CBMs using mean: Main intervention on LLM, translate to all","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [14,15,16,17,18,19,20,21]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_negatives_idx_llm:\n\n        d = test_llm_concepts[a].copy()\n        orig_value = d[change-14] \n        d[change-14] = np.mean(test_llm_concepts,axis=0)[change-14]\n        delta = orig_value-d[change-14]\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n\n        b = c_pred[a].copy()\n    \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------\")\nintervention_concept_idxs = [14,15,16,17,18,19,20,21]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_positives_idx_llm:\n\n        d = test_llm_concepts[a].copy()\n        orig_value = d[change-14] \n        d[change-14] = np.mean(test_llm_concepts,axis=0)[change-14]\n        delta = orig_value-d[change-14]\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n\n        b = c_pred[a].copy()\n    \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:41.172153Z","iopub.execute_input":"2025-04-11T17:26:41.172464Z","iopub.status.idle":"2025-04-11T17:26:41.369351Z","shell.execute_reply.started":"2025-04-11T17:26:41.172437Z","shell.execute_reply":"2025-04-11T17:26:41.368223Z"}},"outputs":[{"name":"stdout","text":"Intervention index 14 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 15 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 16 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 17 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 18 False negatives corrections: 0.36363636363636365 8 22\nIntervention index 19 False negatives corrections: 0.2727272727272727 6 22\nIntervention index 20 False negatives corrections: 0.3181818181818182 7 22\nIntervention index 21 False negatives corrections: 0.18181818181818182 4 22\n----------------\nIntervention index 14 False positives corrections: 0.14545454545454545 8 55\nIntervention index 15 False positives corrections: 0.16363636363636364 9 55\nIntervention index 16 False positives corrections: 0.2 11 55\nIntervention index 17 False positives corrections: 0.16363636363636364 9 55\nIntervention index 18 False positives corrections: 0.18181818181818182 10 55\nIntervention index 19 False positives corrections: 0.14545454545454545 8 55\nIntervention index 20 False positives corrections: 0.18181818181818182 10 55\nIntervention index 21 False positives corrections: 0.16363636363636364 9 55\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"## Correlated corrections over enhanced CBMs using median: Main intervention on LLM, translate to all","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [14,15,16,17,18,19,20,21]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_negatives_idx_llm:\n\n        d = test_llm_concepts[a].copy()\n        orig_value = d[change-14] \n        d[change-14] = np.median(test_llm_concepts,axis=0)[change-14]\n        delta = orig_value-d[change-14]\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n\n        b = c_pred[a].copy()\n    \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------\")\nintervention_concept_idxs = [14,15,16,17,18,19,20,21]\n\nfor change in intervention_concept_idxs:\n    count = 0\n    total = 0\n\n    for a in false_positives_idx_llm:\n\n        d = test_llm_concepts[a].copy()\n        orig_value = d[change-14] \n        d[change-14] = np.median(test_llm_concepts,axis=0)[change-14]\n        delta = orig_value-d[change-14]\n        \n        for val in [q for q in range(14,22) if q!=change]:\n            \n            d[val-14] = d[val-14] + corr[change,val]*delta\n\n        b = c_pred[a].copy()\n    \n        for val in [q for q in range(14) if q!=change]:\n            \n            b[val] = b[val] + corr[change,val]*delta\n        \n        with torch.no_grad():\n            p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Intervention index\",change,\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:41.370323Z","iopub.execute_input":"2025-04-11T17:26:41.370637Z","iopub.status.idle":"2025-04-11T17:26:41.630933Z","shell.execute_reply.started":"2025-04-11T17:26:41.370601Z","shell.execute_reply":"2025-04-11T17:26:41.629888Z"}},"outputs":[{"name":"stdout","text":"Intervention index 14 False negatives corrections: 0.3181818181818182 7 22\nIntervention index 15 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 16 False negatives corrections: 0.22727272727272727 5 22\nIntervention index 17 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 18 False negatives corrections: 0.13636363636363635 3 22\nIntervention index 19 False negatives corrections: 0.18181818181818182 4 22\nIntervention index 20 False negatives corrections: 0.36363636363636365 8 22\nIntervention index 21 False negatives corrections: 0.18181818181818182 4 22\n----------------\nIntervention index 14 False positives corrections: 0.10909090909090909 6 55\nIntervention index 15 False positives corrections: 0.16363636363636364 9 55\nIntervention index 16 False positives corrections: 0.14545454545454545 8 55\nIntervention index 17 False positives corrections: 0.16363636363636364 9 55\nIntervention index 18 False positives corrections: 0.2545454545454545 14 55\nIntervention index 19 False positives corrections: 0.18181818181818182 10 55\nIntervention index 20 False positives corrections: 0.14545454545454545 8 55\nIntervention index 21 False positives corrections: 0.16363636363636364 9 55\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Correlated concept: Multiple main interventions using ground truth, translated to all, including LLMs","metadata":{}},{"cell_type":"code","source":"count = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n\n    b = c_pred[a].copy()\n\n    orig_value1 = b[1]\n    b[1] = test_concepts[a][1]\n    delta1 = orig_value1 - b[1]\n\n    orig_value2 = b[12]\n    b[12] = test_concepts[a][12]\n    delta2 = orig_value2 - b[12]\n\n    d = test_llm_concepts[a].copy()\n    orig_value3 = d[5] \n    d[5] = 1.0\n    delta3 = orig_value-d[5]\n\n    for val in [q for q in range(14) if q not in [1,12]]:\n        \n        b[val] = b[val] + corr[1,val]*delta1 + corr[12,val]*delta2 + corr[19,val]*delta3\n    \n    d = test_llm_concepts[a].copy()\n    \n    for val in [q for q in range(14,22) if q not in [19]]:\n        \n        d[val-14] = d[val-14] + corr[1,val]*delta1 + corr[12,val]*delta2 + corr[19,val]*delta3\n\n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------------\")\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx_llm:\n\n    b = c_pred[a].copy()\n\n    orig_value1 = b[12]\n    b[12] = test_concepts[a][12]\n    delta1 = orig_value1 - b[12]\n\n    orig_value2 = b[13]\n    b[13] = test_concepts[a][13]\n    delta2 = orig_value2 - b[13]\n\n    d = test_llm_concepts[a].copy()\n    orig_value3 = d[6] \n    d[6] = 0.0\n    delta3 = orig_value-d[6]\n    \n    for val in [q for q in range(14) if q not in [12,13]]:\n        \n        b[val] = b[val] + corr[13,val]*delta2  + corr[12,val]*delta1 + corr[20,val]*delta3\n    \n    for val in [q for q in range(14,22) if q not in [20]]:\n        \n        d[val-14] = d[val-14] + corr[13,val]*delta2 + corr[12,val]*delta1 + corr[20,val]*delta3\n\n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:41.631996Z","iopub.execute_input":"2025-04-11T17:26:41.632366Z","iopub.status.idle":"2025-04-11T17:26:41.670809Z","shell.execute_reply.started":"2025-04-11T17:26:41.632333Z","shell.execute_reply":"2025-04-11T17:26:41.669604Z"}},"outputs":[{"name":"stdout","text":"False negatives corrections: 0.8181818181818182 18 22\n----------------------\nFalse positives corrections: 0.8181818181818182 45 55\n","output_type":"stream"}],"execution_count":58},{"cell_type":"markdown","source":"## Correlated concept: Multiple main interventions using mean, translated to all, including LLMs","metadata":{}},{"cell_type":"code","source":"count = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n\n    b = c_pred[a].copy()\n\n    orig_value1 = b[1]\n    b[1] = np.mean(test_concepts,axis=0)[1]\n    delta1 = orig_value1 - b[1]\n\n    orig_value2 = b[12]\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    delta2 = orig_value2 - b[12]\n\n    d = test_llm_concepts[a].copy()\n    orig_value3 = d[5] \n    d[5] = np.mean(test_llm_concepts,axis=0)[5]\n    delta3 = orig_value-d[5]\n\n    for val in [q for q in range(14) if q not in [1,12]]:\n        \n        b[val] = b[val] + corr[1,val]*delta1 + corr[12,val]*delta2 + corr[19,val]*delta3\n    \n    d = test_llm_concepts[a].copy()\n    \n    for val in [q for q in range(14,22) if q not in [19]]:\n        \n        d[val-14] = d[val-14] + corr[1,val]*delta1 + corr[12,val]*delta2 + corr[19,val]*delta3\n\n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------------\")\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx_llm:\n\n    b = c_pred[a].copy()\n\n    orig_value1 = b[12]\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    delta1 = orig_value1 - b[12]\n\n    orig_value2 = b[13]\n    b[13] = np.mean(test_concepts,axis=0)[13]\n    delta2 = orig_value2 - b[13]\n\n    d = test_llm_concepts[a].copy()\n    orig_value3 = d[6] \n    d[6] = np.mean(test_llm_concepts,axis=0)[6]\n    delta3 = orig_value-d[6]\n    \n    for val in [q for q in range(14) if q not in [12,13]]:\n        \n        b[val] = b[val] + corr[13,val]*delta2  + corr[12,val]*delta1 + corr[20,val]*delta3\n    \n    for val in [q for q in range(14,22) if q not in [20]]:\n        \n        d[val-14] = d[val-14] + corr[13,val]*delta2 + corr[12,val]*delta1 + corr[20,val]*delta3\n\n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:41.671836Z","iopub.execute_input":"2025-04-11T17:26:41.672160Z","iopub.status.idle":"2025-04-11T17:26:41.719678Z","shell.execute_reply.started":"2025-04-11T17:26:41.672132Z","shell.execute_reply":"2025-04-11T17:26:41.718523Z"}},"outputs":[{"name":"stdout","text":"False negatives corrections: 0.6818181818181818 15 22\n----------------------\nFalse positives corrections: 0.5636363636363636 31 55\n","output_type":"stream"}],"execution_count":59},{"cell_type":"markdown","source":"## Correlated concept: Multiple main interventions using median, translated to all, including LLMs","metadata":{}},{"cell_type":"code","source":"count = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n\n    b = c_pred[a].copy()\n\n    orig_value1 = b[1]\n    b[1] = np.mean(test_concepts,axis=0)[1]\n    delta1 = orig_value1 - b[1]\n\n    orig_value2 = b[12]\n    b[12] = np.mean(test_concepts,axis=0)[12]\n    delta2 = orig_value2 - b[12]\n\n    d = test_llm_concepts[a].copy()\n    orig_value3 = d[5] \n    d[5] = np.mean(test_llm_concepts,axis=0)[5]\n    delta3 = orig_value-d[5]\n\n    for val in [q for q in range(14) if q not in [1,12]]:\n        \n        b[val] = b[val] + corr[1,val]*delta1 + corr[12,val]*delta2 + corr[19,val]*delta3\n    \n    d = test_llm_concepts[a].copy()\n    \n    for val in [q for q in range(14,22) if q not in [19]]:\n        \n        d[val-14] = d[val-14] + corr[1,val]*delta1 + corr[12,val]*delta2 + corr[19,val]*delta3\n\n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n\n    if p_int>=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count, total)\n\nprint(\"----------------------\")\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx_llm:\n\n    b = c_pred[a].copy()\n\n    orig_value1 = b[12]\n    b[12] = np.median(test_concepts,axis=0)[12]\n    delta1 = orig_value1 - b[12]\n\n    orig_value2 = b[13]\n    b[13] = np.median(test_concepts,axis=0)[13]\n    delta2 = orig_value2 - b[13]\n\n    idx = 6\n    d = test_llm_concepts[a].copy()\n    orig_value3 = d[idx] \n    d[idx] = np.median(test_llm_concepts,axis=0)[idx]\n    delta3 = orig_value-d[idx]\n    \n    for val in [q for q in range(14) if q not in [12,13]]:\n        \n        b[val] = b[val] + corr[13,val]*delta2  + corr[12,val]*delta1 + corr[idx+14,val]*delta3\n    \n    for val in [q for q in range(14,22) if q not in [idx+14]]:\n        \n        d[val-14] = d[val-14] + corr[13,val]*delta2 + corr[12,val]*delta1 + corr[idx+14,val]*delta3\n\n    with torch.no_grad():\n        p_int = model_int6(torch.tensor(test_features[a:a+1]),torch.tensor([b[-2:]]),torch.tensor([b[:-2]]),torch.tensor([d]))\n\n    if p_int<=0.5:\n        count+=1\n    total+=1\n    \nprint(\"False positives corrections:\",count/total,count, total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:41.720849Z","iopub.execute_input":"2025-04-11T17:26:41.721258Z","iopub.status.idle":"2025-04-11T17:26:41.793122Z","shell.execute_reply.started":"2025-04-11T17:26:41.721202Z","shell.execute_reply":"2025-04-11T17:26:41.792038Z"}},"outputs":[{"name":"stdout","text":"False negatives corrections: 0.6818181818181818 15 22\n----------------------\nFalse positives corrections: 0.6363636363636364 35 55\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Correlated Concept corrections over vanilla CBMs","metadata":{}},{"cell_type":"markdown","source":"### GT","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n\nfor change in intervention_concept_idxs:\n\n    count = 0\n    total = 0\n    \n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = test_concepts[a][change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(12) if q!=change]:\n            #orig = b[val]\n            #new = test_concepts[a][val]\n            #delta = orig-new\n            \n            b[val] = b[val] + corr[change,val]*delta\n            \n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",change,\"False negatives corrections:\",count/total,count,total)\n\nfor change in intervention_concept_idxs:\n\n    count = 0\n    total = 0\n    \n    for a in false_positives_idx:\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = test_concepts[a][change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(12) if q!=change]:\n            #orig = b[val]\n            #new = test_concepts[a][val]\n            #delta = orig-new\n            \n            b[val] = b[val] + corr[change,val]*delta\n            \n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",change,\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:41.794123Z","iopub.execute_input":"2025-04-11T17:26:41.794430Z","iopub.status.idle":"2025-04-11T17:26:42.111710Z","shell.execute_reply.started":"2025-04-11T17:26:41.794402Z","shell.execute_reply":"2025-04-11T17:26:42.110265Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.03896103896103896 3 77\nInt concept 1 False negatives corrections: 0.06493506493506493 5 77\nInt concept 2 False negatives corrections: 0.18181818181818182 14 77\nInt concept 3 False negatives corrections: 0.1038961038961039 8 77\nInt concept 4 False negatives corrections: 0.06493506493506493 5 77\nInt concept 5 False negatives corrections: 0.07792207792207792 6 77\nInt concept 6 False negatives corrections: 0.24675324675324675 19 77\nInt concept 7 False negatives corrections: 0.06493506493506493 5 77\nInt concept 8 False negatives corrections: 0.06493506493506493 5 77\nInt concept 9 False negatives corrections: 0.06493506493506493 5 77\nInt concept 10 False negatives corrections: 0.4675324675324675 36 77\nInt concept 11 False negatives corrections: 0.06493506493506493 5 77\nInt concept 0 False positives corrections: 0.6086956521739131 28 46\nInt concept 1 False positives corrections: 0.8913043478260869 41 46\nInt concept 2 False positives corrections: 0.8478260869565217 39 46\nInt concept 3 False positives corrections: 0.8478260869565217 39 46\nInt concept 4 False positives corrections: 0.8695652173913043 40 46\nInt concept 5 False positives corrections: 0.8260869565217391 38 46\nInt concept 6 False positives corrections: 0.717391304347826 33 46\nInt concept 7 False positives corrections: 0.8695652173913043 40 46\nInt concept 8 False positives corrections: 0.8478260869565217 39 46\nInt concept 9 False positives corrections: 0.8695652173913043 40 46\nInt concept 10 False positives corrections: 0.5434782608695652 25 46\nInt concept 11 False positives corrections: 0.8913043478260869 41 46\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"### Mean","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n\nfor change in intervention_concept_idxs:\n\n    count = 0\n    total = 0\n    \n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = np.mean(test_concepts,axis=0)[change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(12) if q!=change]:\n            #orig = b[val]\n            #new = test_concepts[a][val]\n            #delta = orig-new\n            \n            b[val] = b[val] + corr[change,val]*delta\n            \n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",change,\"False negatives corrections:\",count/total,count,total)\n\nfor change in intervention_concept_idxs:\n\n    count = 0\n    total = 0\n    \n    for a in false_positives_idx:\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = np.mean(test_concepts,axis=0)[change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(12) if q!=change]:\n            #orig = b[val]\n            #new = test_concepts[a][val]\n            #delta = orig-new\n            \n            b[val] = b[val] + corr[change,val]*delta\n            \n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",change,\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:42.112748Z","iopub.execute_input":"2025-04-11T17:26:42.113114Z","iopub.status.idle":"2025-04-11T17:26:42.544526Z","shell.execute_reply.started":"2025-04-11T17:26:42.113074Z","shell.execute_reply":"2025-04-11T17:26:42.543352Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.05194805194805195 4 77\nInt concept 1 False negatives corrections: 0.06493506493506493 5 77\nInt concept 2 False negatives corrections: 0.025974025974025976 2 77\nInt concept 3 False negatives corrections: 0.1038961038961039 8 77\nInt concept 4 False negatives corrections: 0.06493506493506493 5 77\nInt concept 5 False negatives corrections: 0.07792207792207792 6 77\nInt concept 6 False negatives corrections: 0.18181818181818182 14 77\nInt concept 7 False negatives corrections: 0.06493506493506493 5 77\nInt concept 8 False negatives corrections: 0.06493506493506493 5 77\nInt concept 9 False negatives corrections: 0.06493506493506493 5 77\nInt concept 10 False negatives corrections: 0.33766233766233766 26 77\nInt concept 11 False negatives corrections: 0.06493506493506493 5 77\nInt concept 0 False positives corrections: 0.6086956521739131 28 46\nInt concept 1 False positives corrections: 0.8695652173913043 40 46\nInt concept 2 False positives corrections: 0.6956521739130435 32 46\nInt concept 3 False positives corrections: 0.8478260869565217 39 46\nInt concept 4 False positives corrections: 0.8695652173913043 40 46\nInt concept 5 False positives corrections: 0.8478260869565217 39 46\nInt concept 6 False positives corrections: 0.6956521739130435 32 46\nInt concept 7 False positives corrections: 0.8695652173913043 40 46\nInt concept 8 False positives corrections: 0.8695652173913043 40 46\nInt concept 9 False positives corrections: 0.8695652173913043 40 46\nInt concept 10 False positives corrections: 0.6086956521739131 28 46\nInt concept 11 False positives corrections: 0.8913043478260869 41 46\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"### Median","metadata":{}},{"cell_type":"code","source":"intervention_concept_idxs = [0,1,2,3,4,5,6,7,8,9,10,11]\n\nfor change in intervention_concept_idxs:\n\n    count = 0\n    total = 0\n    \n    for a in false_negatives_idx:\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = np.median(test_concepts,axis=0)[change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(12) if q!=change]:\n            #orig = b[val]\n            #new = test_concepts[a][val]\n            #delta = orig-new\n            \n            b[val] = b[val] + corr[change,val]*delta\n            \n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int>=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",change,\"False negatives corrections:\",count/total,count,total)\n\nfor change in intervention_concept_idxs:\n\n    count = 0\n    total = 0\n    \n    for a in false_positives_idx:\n        b = c_pred[a].copy()\n    \n        orig_value = b[change] \n        b[change] = np.median(test_concepts,axis=0)[change]\n        delta = orig_value-b[change]\n        \n        for val in [q for q in range(12) if q!=change]:\n            #orig = b[val]\n            #new = test_concepts[a][val]\n            #delta = orig-new\n            \n            b[val] = b[val] + corr[change,val]*delta\n            \n        b = b[:-2]\n        \n        p_int = model_int2(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float())\n    \n        if p_int<=0.5:\n            count+=1\n        total+=1\n        \n    print(\"Int concept\",change,\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:42.545607Z","iopub.execute_input":"2025-04-11T17:26:42.545920Z","iopub.status.idle":"2025-04-11T17:26:43.229788Z","shell.execute_reply.started":"2025-04-11T17:26:42.545882Z","shell.execute_reply":"2025-04-11T17:26:43.228601Z"}},"outputs":[{"name":"stdout","text":"Int concept 0 False negatives corrections: 0.06493506493506493 5 77\nInt concept 1 False negatives corrections: 0.06493506493506493 5 77\nInt concept 2 False negatives corrections: 0.012987012987012988 1 77\nInt concept 3 False negatives corrections: 0.1038961038961039 8 77\nInt concept 4 False negatives corrections: 0.06493506493506493 5 77\nInt concept 5 False negatives corrections: 0.07792207792207792 6 77\nInt concept 6 False negatives corrections: 0.24675324675324675 19 77\nInt concept 7 False negatives corrections: 0.06493506493506493 5 77\nInt concept 8 False negatives corrections: 0.06493506493506493 5 77\nInt concept 9 False negatives corrections: 0.06493506493506493 5 77\nInt concept 10 False negatives corrections: 0.36363636363636365 28 77\nInt concept 11 False negatives corrections: 0.06493506493506493 5 77\nInt concept 0 False positives corrections: 0.6086956521739131 28 46\nInt concept 1 False positives corrections: 0.8695652173913043 40 46\nInt concept 2 False positives corrections: 0.9347826086956522 43 46\nInt concept 3 False positives corrections: 0.8478260869565217 39 46\nInt concept 4 False positives corrections: 0.8695652173913043 40 46\nInt concept 5 False positives corrections: 0.8043478260869565 37 46\nInt concept 6 False positives corrections: 0.6956521739130435 32 46\nInt concept 7 False positives corrections: 0.8695652173913043 40 46\nInt concept 8 False positives corrections: 0.8913043478260869 41 46\nInt concept 9 False positives corrections: 0.8695652173913043 40 46\nInt concept 10 False positives corrections: 0.5869565217391305 27 46\nInt concept 11 False positives corrections: 0.8913043478260869 41 46\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Case studies","metadata":{}},{"cell_type":"code","source":"true_positives_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.230842Z","iopub.execute_input":"2025-04-11T17:26:43.231355Z","iopub.status.idle":"2025-04-11T17:26:43.238796Z","shell.execute_reply.started":"2025-04-11T17:26:43.231313Z","shell.execute_reply":"2025-04-11T17:26:43.237451Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"array([  0,   1,   2,   3,  10,  12,  19,  24,  35,  36,  37,  38,  44,\n        45,  50,  51,  53,  56,  57,  58,  67,  76,  77,  84,  85,  88,\n        92,  94, 106, 107, 108, 113, 116, 117, 120, 123, 125, 126, 129,\n       130, 131, 133, 135, 137, 140, 145, 147, 150, 157, 159, 160, 161,\n       164, 165, 166, 167, 172, 173, 174, 175, 180, 189, 191, 192, 195,\n       198, 200, 202, 204, 212, 213, 219, 220, 221, 227, 231, 237, 239,\n       240, 251, 253, 257, 259, 262, 265, 273, 275, 280, 283, 289, 291,\n       293, 296, 297, 299, 301, 303, 307, 311, 313, 320, 322, 323, 325,\n       326, 330, 334, 335, 336, 339, 342, 348, 356, 357, 360, 363, 364,\n       365, 366, 367, 369, 370, 371, 373, 375, 376, 377, 382, 384, 389,\n       390])"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"false_positives_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.239787Z","iopub.execute_input":"2025-04-11T17:26:43.240103Z","iopub.status.idle":"2025-04-11T17:26:43.259001Z","shell.execute_reply.started":"2025-04-11T17:26:43.240072Z","shell.execute_reply":"2025-04-11T17:26:43.257873Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"array([  7,  15,  18,  22,  25,  33,  54,  74,  82,  98, 100, 101, 110,\n       114, 118, 134, 142, 144, 171, 177, 178, 181, 184, 186, 201, 208,\n       209, 214, 217, 218, 223, 234, 236, 247, 248, 252, 258, 279, 288,\n       292, 315, 318, 327, 350, 368, 388])"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"false_negatives_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.259935Z","iopub.execute_input":"2025-04-11T17:26:43.260217Z","iopub.status.idle":"2025-04-11T17:26:43.281114Z","shell.execute_reply.started":"2025-04-11T17:26:43.260193Z","shell.execute_reply":"2025-04-11T17:26:43.280033Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"array([  8,   9,  11,  14,  16,  31,  39,  46,  49,  52,  55,  59,  62,\n        64,  66,  68,  73,  93, 102, 103, 105, 119, 121, 127, 128, 132,\n       139, 149, 152, 153, 154, 158, 169, 170, 179, 182, 185, 188, 193,\n       199, 205, 207, 210, 215, 225, 226, 230, 232, 249, 255, 263, 264,\n       266, 269, 272, 274, 281, 282, 284, 287, 294, 305, 310, 312, 317,\n       331, 340, 346, 347, 349, 353, 358, 362, 374, 380, 386, 387])"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"false_positives_idx_llm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.282294Z","iopub.execute_input":"2025-04-11T17:26:43.282625Z","iopub.status.idle":"2025-04-11T17:26:43.302779Z","shell.execute_reply.started":"2025-04-11T17:26:43.282595Z","shell.execute_reply":"2025-04-11T17:26:43.301605Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array([  7,  22,  23,  25,  33,  42,  54,  60,  65,  69,  79,  82,  83,\n        91,  95,  98, 100, 101, 104, 111, 134, 136, 141, 144, 168, 171,\n       177, 178, 181, 184, 186, 201, 206, 209, 214, 217, 218, 222, 223,\n       245, 248, 254, 270, 288, 315, 318, 327, 328, 333, 350, 361, 368,\n       372, 378, 388])"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"false_negatives_idx_llm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.311507Z","iopub.execute_input":"2025-04-11T17:26:43.311880Z","iopub.status.idle":"2025-04-11T17:26:43.323975Z","shell.execute_reply.started":"2025-04-11T17:26:43.311848Z","shell.execute_reply":"2025-04-11T17:26:43.322946Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"array([  8,   9,  16,  52,  59,  62,  93, 107, 128, 158, 182, 188, 191,\n       193, 195, 220, 226, 281, 296, 317, 331, 374])"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"test_concepts.shape, test_llm_concepts.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.326159Z","iopub.execute_input":"2025-04-11T17:26:43.326464Z","iopub.status.idle":"2025-04-11T17:26:43.343521Z","shell.execute_reply.started":"2025-04-11T17:26:43.326428Z","shell.execute_reply":"2025-04-11T17:26:43.342251Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"((391, 14), (391, 8))"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"np.setdiff1d(false_negatives_idx_llm, false_negatives_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.344470Z","iopub.execute_input":"2025-04-11T17:26:43.344860Z","iopub.status.idle":"2025-04-11T17:26:43.363396Z","shell.execute_reply.started":"2025-04-11T17:26:43.344818Z","shell.execute_reply":"2025-04-11T17:26:43.362229Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"array([107, 191, 195, 220, 296])"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"np.setdiff1d(false_positives_idx_llm, false_positives_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.364456Z","iopub.execute_input":"2025-04-11T17:26:43.364772Z","iopub.status.idle":"2025-04-11T17:26:43.385500Z","shell.execute_reply.started":"2025-04-11T17:26:43.364745Z","shell.execute_reply":"2025-04-11T17:26:43.384414Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"array([ 23,  42,  60,  65,  69,  79,  83,  91,  95, 104, 111, 136, 141,\n       168, 206, 222, 245, 254, 270, 328, 333, 361, 372, 378])"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"def patient_info(idx):\n    features_list = ['max_norepinephrine_equiv', 'avg_norepinephrine_equiv', 'sofa_cardiovascular_avg_meanbp',\n                      'sofa_cardiovascular_avg_rate_norepinephrine', 'sofa_respiration_avg_pao2fio2ratio',\n                      'sofa_renal_avg_urineoutput', 'sofa_renal_avg_creatinine', 'sofa_cns_avg_gcs', \n                     'first24hr_cardiovascular_meanbp','sofa_cardiovascular_worst_meanbp',\n                      'sofa_cardiovascular_worst_rate_norepinephrine', 'sofa_respiration_worst_pao2fio2ratio',\n                      'sofa_renal_worst_urineoutput', 'sofa_cns_worst_gcs','mech_vent_duration_minutes']\n    \n    features = processor.x_scaler.inverse_transform(test_features[idx:idx+1,:15])\n\n    features_binary_list = ['other_respiratory_diseases', 'lung_diseases_due_to_external_agents',\n                         'chronic_lower_respiratory_diseases', 'acute_lower_respiratory_infections',\n                         'influenza_pneumonia', 'upper_respiratory_infections']\n    \n    features_binary = test_features[idx:idx+1,15:]\n    \n    print(\"--------Features-------\")\n    for i in range(15):\n        print(features_list[i], features[0,i])\n    for i in range(15,21):\n        print(features_binary_list[15-i],features_binary[0,15-i])\n    \n    concept_list = ['c_sofa_avg_cardiovascular', 'c_sofa_avg_respiration', 'c_sofa_avg_renal', \n                    'c_sofa_avg_cns', 'c_first24hr_sofa_max_cardiovascular', 'c_first24hr_sofa_max_respiration', \n                    'c_first24hr_sofa_max_renal', 'c_first24hr_sofa_max_cns', 'c_sofa_max_cardiovascular', \n                    'c_sofa_max_respiration', 'c_sofa_max_renal', 'c_sofa_max_cns']\n    \n    concept_bin_list = ['c_svr_resp_comorbidity', 'c_mod_resp_comorbidity']\n    \n    true_cont_concepts = processor.c_scaler.inverse_transform(test_concepts[idx:idx+1,:12])\n    pred_cont_concepts = processor.c_scaler.inverse_transform(c_pred[idx:idx+1,:12])\n    true_binary_concepts = test_concepts[idx:idx+1,12:14]\n    pred_binary_concepts = c_pred[idx:idx+1,12:14]\n    llm_list = list(LLM_C.columns)\n    llm_concepts = test_llm_concepts[idx:idx+1]\n    \n    print(\"--------Concepts--------\")\n    for i in range(12):\n        print(concept_list[i],\"True:\",true_cont_concepts[0,i],\"Pred:\",pred_cont_concepts[0,i])\n    for i in range(2):\n        print(concept_bin_list[i],\"True:\",true_binary_concepts[0,i],\"Pred:\",pred_binary_concepts[0,i])\n    \n    for i in range(8):\n        print(llm_list[i],llm_concepts[0,i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.386830Z","iopub.execute_input":"2025-04-11T17:26:43.387209Z","iopub.status.idle":"2025-04-11T17:26:43.407815Z","shell.execute_reply.started":"2025-04-11T17:26:43.387178Z","shell.execute_reply":"2025-04-11T17:26:43.406620Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"y_pred[0], y_pred[1], y_pred[2], y_pred[3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.409005Z","iopub.execute_input":"2025-04-11T17:26:43.409428Z","iopub.status.idle":"2025-04-11T17:26:43.437820Z","shell.execute_reply.started":"2025-04-11T17:26:43.409388Z","shell.execute_reply":"2025-04-11T17:26:43.436633Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"(0.58577484, 0.5937679, 0.8659679, 0.9416028)"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"patient_info(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.439130Z","iopub.execute_input":"2025-04-11T17:26:43.439727Z","iopub.status.idle":"2025-04-11T17:26:43.479306Z","shell.execute_reply.started":"2025-04-11T17:26:43.439677Z","shell.execute_reply":"2025-04-11T17:26:43.476166Z"}},"outputs":[{"name":"stdout","text":"--------Features-------\nmax_norepinephrine_equiv 0.25059998\navg_norepinephrine_equiv 0.0730783\nsofa_cardiovascular_avg_meanbp 77.1\nsofa_cardiovascular_avg_rate_norepinephrine 0.07346412\nsofa_respiration_avg_pao2fio2ratio 166.39394\nsofa_renal_avg_urineoutput 2067.5427\nsofa_renal_avg_creatinine 1.1185185\nsofa_cns_avg_gcs 14.815789\nfirst24hr_cardiovascular_meanbp 81.0\nsofa_cardiovascular_worst_meanbp 68.0\nsofa_cardiovascular_worst_rate_norepinephrine 0.15043026\nsofa_respiration_worst_pao2fio2ratio 88.0\nsofa_renal_worst_urineoutput 436.73465\nsofa_cns_worst_gcs 5.0\nmech_vent_duration_minutes 14459.999\nother_respiratory_diseases 1.0\nupper_respiratory_infections 0.0\ninfluenza_pneumonia 0.0\nacute_lower_respiratory_infections 0.0\nchronic_lower_respiratory_diseases 0.0\nlung_diseases_due_to_external_agents 1.0\n--------Concepts--------\nc_sofa_avg_cardiovascular True: 1.4495413 Pred: 0.14781882\nc_sofa_avg_respiration True: 2.848485 Pred: 3.7923257\nc_sofa_avg_renal True: 0.22362868 Pred: 0.9881459\nc_sofa_avg_cns True: 0.10526316 Pred: 1.4908702\nc_first24hr_sofa_max_cardiovascular True: 4.0 Pred: 3.8388221\nc_first24hr_sofa_max_respiration True: 4.0 Pred: 0.11981967\nc_first24hr_sofa_max_renal True: 1.0 Pred: 2.5807238\nc_first24hr_sofa_max_cns True: 0.0 Pred: 1.8997098\nc_sofa_max_cardiovascular True: 4.0 Pred: 1.143439\nc_sofa_max_respiration True: 4.0 Pred: 2.495193\nc_sofa_max_renal True: 3.0 Pred: 4.2042994\nc_sofa_max_cns True: 4.0 Pred: 4.2490206\nc_svr_resp_comorbidity True: 0.0 Pred: 0.83707225\nc_mod_resp_comorbidity True: 1.0 Pred: 0.90243584\nards_detected 1.0\naspiration_detected 0.0\nbilateral_infiltrates_detected 1.0\ncardiac_arrest_detected 0.0\ncardiac_failure_detected 1.0\npancreatitis_detected 0.0\npneumonia_detected 1.0\ntrali_detected 1.0\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"patient_info(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.482648Z","iopub.execute_input":"2025-04-11T17:26:43.482983Z","iopub.status.idle":"2025-04-11T17:26:43.517990Z","shell.execute_reply.started":"2025-04-11T17:26:43.482953Z","shell.execute_reply":"2025-04-11T17:26:43.516918Z"}},"outputs":[{"name":"stdout","text":"--------Features-------\nmax_norepinephrine_equiv 0.20019999\navg_norepinephrine_equiv 0.084288724\nsofa_cardiovascular_avg_meanbp 91.6631\nsofa_cardiovascular_avg_rate_norepinephrine 0.07451578\nsofa_respiration_avg_pao2fio2ratio 145.34703\nsofa_renal_avg_urineoutput 221.62918\nsofa_renal_avg_creatinine 4.418182\nsofa_cns_avg_gcs 13.817073\nfirst24hr_cardiovascular_meanbp 68.0\nsofa_cardiovascular_worst_meanbp 80.0\nsofa_cardiovascular_worst_rate_norepinephrine 0.10002754\nsofa_respiration_worst_pao2fio2ratio 83.0\nsofa_renal_worst_urineoutput 80.99999\nsofa_cns_worst_gcs 3.0\nmech_vent_duration_minutes 18060.0\nother_respiratory_diseases 1.0\nupper_respiratory_infections 0.0\ninfluenza_pneumonia 1.0\nacute_lower_respiratory_infections 0.0\nchronic_lower_respiratory_diseases 0.0\nlung_diseases_due_to_external_agents 1.0\n--------Concepts--------\nc_sofa_avg_cardiovascular True: 0.47860962 Pred: 3.9420629\nc_sofa_avg_respiration True: 3.0 Pred: 2.1404853\nc_sofa_avg_renal True: 3.4114585 Pred: -0.22874808\nc_sofa_avg_cns True: 0.42682925 Pred: 1.5156498\nc_first24hr_sofa_max_cardiovascular True: 4.0 Pred: 7.9763446\nc_first24hr_sofa_max_respiration True: 4.0 Pred: 0.08458787\nc_first24hr_sofa_max_renal True: 3.0 Pred: 2.243961\nc_first24hr_sofa_max_cns True: 4.0 Pred: 1.742238\nc_sofa_max_cardiovascular True: 4.0 Pred: 3.2866654\nc_sofa_max_respiration True: 4.0 Pred: 2.8673258\nc_sofa_max_renal True: 4.0 Pred: 3.8120892\nc_sofa_max_cns True: 4.0 Pred: 4.171567\nc_svr_resp_comorbidity True: 1.0 Pred: 1.20917\nc_mod_resp_comorbidity True: 0.0 Pred: 0.9842539\nards_detected 1.0\naspiration_detected 1.0\nbilateral_infiltrates_detected 1.0\ncardiac_arrest_detected 0.0\ncardiac_failure_detected 1.0\npancreatitis_detected 0.0\npneumonia_detected 1.0\ntrali_detected 0.0\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_cont[['max_norepinephrine_equiv', 'avg_norepinephrine_equiv', 'sofa_cardiovascular_avg_meanbp',\n      'sofa_cardiovascular_avg_rate_norepinephrine', 'sofa_respiration_avg_pao2fio2ratio',\n      'sofa_renal_avg_urineoutput', 'sofa_renal_avg_creatinine', 'sofa_cns_avg_gcs', 'first24hr_cardiovascular_meanbp',\n      'sofa_cardiovascular_worst_meanbp',\n      'sofa_cardiovascular_worst_rate_norepinephrine', 'sofa_respiration_worst_pao2fio2ratio',\n      'sofa_renal_worst_urineoutput', 'sofa_cns_worst_gcs',\n      'mech_vent_duration_minutes']].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.518954Z","iopub.execute_input":"2025-04-11T17:26:43.519311Z","iopub.status.idle":"2025-04-11T17:26:43.576576Z","shell.execute_reply.started":"2025-04-11T17:26:43.519271Z","shell.execute_reply":"2025-04-11T17:26:43.575386Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"       max_norepinephrine_equiv  avg_norepinephrine_equiv  \\\ncount               1954.000000               1954.000000   \nmean                   0.870311                  0.146885   \nstd                    3.981872                  0.591864   \nmin                    0.000000                  0.000000   \n25%                    0.100000                  0.044340   \n50%                    0.300400                  0.095712   \n75%                    0.631525                  0.175445   \nmax                  100.110300                 25.396800   \n\n       sofa_cardiovascular_avg_meanbp  \\\ncount                     1954.000000   \nmean                        76.945346   \nstd                          8.427606   \nmin                         54.091667   \n25%                         71.089230   \n50%                         75.956906   \n75%                         82.008346   \nmax                        112.014870   \n\n       sofa_cardiovascular_avg_rate_norepinephrine  \\\ncount                                  1319.000000   \nmean                                      0.134594   \nstd                                       0.097126   \nmin                                       0.012503   \n25%                                       0.064741   \n50%                                       0.105278   \n75%                                       0.175398   \nmax                                       0.676265   \n\n       sofa_respiration_avg_pao2fio2ratio  sofa_renal_avg_urineoutput  \\\ncount                         1951.000000                 1920.000000   \nmean                           210.566431                 2087.808411   \nstd                             52.625603                 1196.591774   \nmin                             58.189474                   -1.211422   \n25%                            174.193328                 1196.169735   \n50%                            206.530021                 2150.340131   \n75%                            245.076077                 2893.864229   \nmax                            409.733432                 7812.156434   \n\n       sofa_renal_avg_creatinine  sofa_cns_avg_gcs  \\\ncount                1952.000000       1954.000000   \nmean                    1.646029         14.518385   \nstd                     1.224079          0.623983   \nmin                     0.100000          5.322581   \n25%                     0.814123         14.375000   \n50%                     1.246761         14.683624   \n75%                     2.109357         14.887671   \nmax                    10.300000         15.000000   \n\n       first24hr_cardiovascular_meanbp  sofa_cardiovascular_worst_meanbp  \\\ncount                      1815.000000                       1886.000000   \nmean                         72.589715                         68.389449   \nstd                          15.624567                         12.193167   \nmin                           1.000000                          1.000000   \n25%                          64.000000                         62.000000   \n50%                          71.000000                         67.750000   \n75%                          80.000000                         74.000000   \nmax                         261.000000                        131.000000   \n\n       sofa_cardiovascular_worst_rate_norepinephrine  \\\ncount                                    1296.000000   \nmean                                        0.183187   \nstd                                         0.132894   \nmin                                         0.010000   \n25%                                         0.100118   \n50%                                         0.149554   \n75%                                         0.222757   \nmax                                         1.141252   \n\n       sofa_respiration_worst_pao2fio2ratio  sofa_renal_worst_urineoutput  \\\ncount                           1951.000000                   1554.000000   \nmean                             129.603604                   1553.551509   \nstd                               53.128289                   1543.058064   \nmin                               33.000000                   -750.000000   \n25%                               86.000000                    188.250000   \n50%                              118.333333                   1074.000000   \n75%                              175.000000                   2503.750000   \nmax                              298.000000                   7675.000000   \n\n       sofa_cns_worst_gcs  mech_vent_duration_minutes  \ncount         1954.000000                 1954.000000  \nmean             8.847492                12725.556295  \nstd              4.421967                11124.264245  \nmin              3.000000                    0.000000  \n25%              4.000000                 5460.000000  \n50%              9.000000                 9420.000000  \n75%             14.000000                16559.500000  \nmax             15.000000                86520.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>max_norepinephrine_equiv</th>\n      <th>avg_norepinephrine_equiv</th>\n      <th>sofa_cardiovascular_avg_meanbp</th>\n      <th>sofa_cardiovascular_avg_rate_norepinephrine</th>\n      <th>sofa_respiration_avg_pao2fio2ratio</th>\n      <th>sofa_renal_avg_urineoutput</th>\n      <th>sofa_renal_avg_creatinine</th>\n      <th>sofa_cns_avg_gcs</th>\n      <th>first24hr_cardiovascular_meanbp</th>\n      <th>sofa_cardiovascular_worst_meanbp</th>\n      <th>sofa_cardiovascular_worst_rate_norepinephrine</th>\n      <th>sofa_respiration_worst_pao2fio2ratio</th>\n      <th>sofa_renal_worst_urineoutput</th>\n      <th>sofa_cns_worst_gcs</th>\n      <th>mech_vent_duration_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n      <td>1319.000000</td>\n      <td>1951.000000</td>\n      <td>1920.000000</td>\n      <td>1952.000000</td>\n      <td>1954.000000</td>\n      <td>1815.000000</td>\n      <td>1886.000000</td>\n      <td>1296.000000</td>\n      <td>1951.000000</td>\n      <td>1554.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.870311</td>\n      <td>0.146885</td>\n      <td>76.945346</td>\n      <td>0.134594</td>\n      <td>210.566431</td>\n      <td>2087.808411</td>\n      <td>1.646029</td>\n      <td>14.518385</td>\n      <td>72.589715</td>\n      <td>68.389449</td>\n      <td>0.183187</td>\n      <td>129.603604</td>\n      <td>1553.551509</td>\n      <td>8.847492</td>\n      <td>12725.556295</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.981872</td>\n      <td>0.591864</td>\n      <td>8.427606</td>\n      <td>0.097126</td>\n      <td>52.625603</td>\n      <td>1196.591774</td>\n      <td>1.224079</td>\n      <td>0.623983</td>\n      <td>15.624567</td>\n      <td>12.193167</td>\n      <td>0.132894</td>\n      <td>53.128289</td>\n      <td>1543.058064</td>\n      <td>4.421967</td>\n      <td>11124.264245</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>54.091667</td>\n      <td>0.012503</td>\n      <td>58.189474</td>\n      <td>-1.211422</td>\n      <td>0.100000</td>\n      <td>5.322581</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.010000</td>\n      <td>33.000000</td>\n      <td>-750.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.100000</td>\n      <td>0.044340</td>\n      <td>71.089230</td>\n      <td>0.064741</td>\n      <td>174.193328</td>\n      <td>1196.169735</td>\n      <td>0.814123</td>\n      <td>14.375000</td>\n      <td>64.000000</td>\n      <td>62.000000</td>\n      <td>0.100118</td>\n      <td>86.000000</td>\n      <td>188.250000</td>\n      <td>4.000000</td>\n      <td>5460.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.300400</td>\n      <td>0.095712</td>\n      <td>75.956906</td>\n      <td>0.105278</td>\n      <td>206.530021</td>\n      <td>2150.340131</td>\n      <td>1.246761</td>\n      <td>14.683624</td>\n      <td>71.000000</td>\n      <td>67.750000</td>\n      <td>0.149554</td>\n      <td>118.333333</td>\n      <td>1074.000000</td>\n      <td>9.000000</td>\n      <td>9420.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.631525</td>\n      <td>0.175445</td>\n      <td>82.008346</td>\n      <td>0.175398</td>\n      <td>245.076077</td>\n      <td>2893.864229</td>\n      <td>2.109357</td>\n      <td>14.887671</td>\n      <td>80.000000</td>\n      <td>74.000000</td>\n      <td>0.222757</td>\n      <td>175.000000</td>\n      <td>2503.750000</td>\n      <td>14.000000</td>\n      <td>16559.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>100.110300</td>\n      <td>25.396800</td>\n      <td>112.014870</td>\n      <td>0.676265</td>\n      <td>409.733432</td>\n      <td>7812.156434</td>\n      <td>10.300000</td>\n      <td>15.000000</td>\n      <td>261.000000</td>\n      <td>131.000000</td>\n      <td>1.141252</td>\n      <td>298.000000</td>\n      <td>7675.000000</td>\n      <td>15.000000</td>\n      <td>86520.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"C_cont[['c_sofa_avg_cardiovascular', 'c_sofa_avg_respiration', 'c_sofa_avg_renal', \n        'c_sofa_avg_cns', 'c_first24hr_sofa_max_cardiovascular', 'c_first24hr_sofa_max_respiration', \n        'c_first24hr_sofa_max_renal', 'c_first24hr_sofa_max_cns', 'c_sofa_max_cardiovascular', \n        'c_sofa_max_respiration', 'c_sofa_max_renal', 'c_sofa_max_cns']].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.577440Z","iopub.execute_input":"2025-04-11T17:26:43.577777Z","iopub.status.idle":"2025-04-11T17:26:43.620181Z","shell.execute_reply.started":"2025-04-11T17:26:43.577748Z","shell.execute_reply":"2025-04-11T17:26:43.619041Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"       c_sofa_avg_cardiovascular  c_sofa_avg_respiration  c_sofa_avg_renal  \\\ncount                1954.000000             1951.000000       1954.000000   \nmean                    1.124533                2.328115          0.617148   \nstd                     1.058069                0.490933          0.997015   \nmin                     0.000000                0.855670          0.000000   \n25%                     0.290368                2.000000          0.005510   \n50%                     0.757726                2.329843          0.110703   \n75%                     1.632093                2.666667          0.733047   \nmax                     4.000000                4.000000          4.000000   \n\n       c_sofa_avg_cns  c_first24hr_sofa_max_cardiovascular  \\\ncount     1954.000000                          1954.000000   \nmean         0.238392                             2.315763   \nstd          0.264275                             1.491085   \nmin          0.000000                             0.000000   \n25%          0.071429                             1.000000   \n50%          0.173762                             3.000000   \n75%          0.314683                             4.000000   \nmax          3.505376                             4.000000   \n\n       c_first24hr_sofa_max_respiration  c_first24hr_sofa_max_renal  \\\ncount                       1954.000000                 1954.000000   \nmean                           2.586489                    1.195496   \nstd                            1.251703                    1.282303   \nmin                            0.000000                    0.000000   \n25%                            2.000000                    0.000000   \n50%                            3.000000                    1.000000   \n75%                            3.000000                    2.000000   \nmax                            4.000000                    4.000000   \n\n       c_first24hr_sofa_max_cns  c_sofa_max_cardiovascular  \\\ncount               1954.000000                1954.000000   \nmean                   0.713408                   2.994371   \nstd                    1.243418                   1.331592   \nmin                    0.000000                   0.000000   \n25%                    0.000000                   1.000000   \n50%                    0.000000                   4.000000   \n75%                    1.000000                   4.000000   \nmax                    4.000000                   4.000000   \n\n       c_sofa_max_respiration  c_sofa_max_renal  c_sofa_max_cns  \ncount             1951.000000       1954.000000     1954.000000  \nmean                 3.415684          2.048106        2.440123  \nstd                  0.597379          1.557480        1.384482  \nmin                  2.000000          0.000000        0.000000  \n25%                  3.000000          1.000000        1.000000  \n50%                  3.000000          2.000000        3.000000  \n75%                  4.000000          4.000000        4.000000  \nmax                  4.000000          4.000000        4.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_sofa_avg_cardiovascular</th>\n      <th>c_sofa_avg_respiration</th>\n      <th>c_sofa_avg_renal</th>\n      <th>c_sofa_avg_cns</th>\n      <th>c_first24hr_sofa_max_cardiovascular</th>\n      <th>c_first24hr_sofa_max_respiration</th>\n      <th>c_first24hr_sofa_max_renal</th>\n      <th>c_first24hr_sofa_max_cns</th>\n      <th>c_sofa_max_cardiovascular</th>\n      <th>c_sofa_max_respiration</th>\n      <th>c_sofa_max_renal</th>\n      <th>c_sofa_max_cns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1954.000000</td>\n      <td>1951.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n      <td>1951.000000</td>\n      <td>1954.000000</td>\n      <td>1954.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.124533</td>\n      <td>2.328115</td>\n      <td>0.617148</td>\n      <td>0.238392</td>\n      <td>2.315763</td>\n      <td>2.586489</td>\n      <td>1.195496</td>\n      <td>0.713408</td>\n      <td>2.994371</td>\n      <td>3.415684</td>\n      <td>2.048106</td>\n      <td>2.440123</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.058069</td>\n      <td>0.490933</td>\n      <td>0.997015</td>\n      <td>0.264275</td>\n      <td>1.491085</td>\n      <td>1.251703</td>\n      <td>1.282303</td>\n      <td>1.243418</td>\n      <td>1.331592</td>\n      <td>0.597379</td>\n      <td>1.557480</td>\n      <td>1.384482</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.855670</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.290368</td>\n      <td>2.000000</td>\n      <td>0.005510</td>\n      <td>0.071429</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.757726</td>\n      <td>2.329843</td>\n      <td>0.110703</td>\n      <td>0.173762</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.632093</td>\n      <td>2.666667</td>\n      <td>0.733047</td>\n      <td>0.314683</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.505376</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test Patient index 31: False negative by Vanilla CBM (0.24), corrected by Enhanced CBM (0.86)","metadata":{}},{"cell_type":"code","source":"y_pred[31], y_pred_llm[31]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.621234Z","iopub.execute_input":"2025-04-11T17:26:43.621656Z","iopub.status.idle":"2025-04-11T17:26:43.627836Z","shell.execute_reply.started":"2025-04-11T17:26:43.621623Z","shell.execute_reply":"2025-04-11T17:26:43.626699Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"(0.2489348, 0.8640127)"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"test_concepts[31], test_llm_concepts[31]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.629014Z","iopub.execute_input":"2025-04-11T17:26:43.629430Z","iopub.status.idle":"2025-04-11T17:26:43.648853Z","shell.execute_reply.started":"2025-04-11T17:26:43.629390Z","shell.execute_reply":"2025-04-11T17:26:43.647564Z"}},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"(array([0.39285713, 0.72704715, 0.5458377 , 0.02113156, 0.25      ,\n        0.        , 0.        , 0.5       , 1.        , 1.        ,\n        1.        , 0.5       , 0.        , 1.        ], dtype=float32),\n array([1., 0., 1., 0., 0., 0., 1., 0.], dtype=float32))"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"c_pred[31], c_pred_llm[31]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.649987Z","iopub.execute_input":"2025-04-11T17:26:43.650391Z","iopub.status.idle":"2025-04-11T17:26:43.672697Z","shell.execute_reply.started":"2025-04-11T17:26:43.650349Z","shell.execute_reply":"2025-04-11T17:26:43.671592Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"(array([3.0823460e-06, 9.9885082e-01, 1.0387356e+00, 1.0186465e+00,\n        7.1420133e-02, 7.7194888e-03, 1.0523874e+00, 5.7827437e-01,\n        5.6075913e-01, 8.8978507e-02, 1.2178097e+00, 8.4553605e-01,\n        4.2539081e-01, 4.6223098e-01], dtype=float32),\n array([ 2.8295588e-05,  9.9593914e-01,  8.3711737e-01,  6.8686098e-01,\n         5.4518235e-01,  4.7256779e-02,  8.4858847e-01,  7.0724684e-01,\n        -5.4663658e-02,  1.7693353e-01,  1.0362664e+00,  9.4690055e-01,\n         9.3202239e-01,  5.9369648e-01], dtype=float32))"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test Patient index 68: False negative by Vanilla CBM (0.24), corrected by Enhanced CBM (0.86)","metadata":{}},{"cell_type":"code","source":"y_pred[68],y_pred_llm[68]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.673814Z","iopub.execute_input":"2025-04-11T17:26:43.674189Z","iopub.status.idle":"2025-04-11T17:26:43.694849Z","shell.execute_reply.started":"2025-04-11T17:26:43.674157Z","shell.execute_reply":"2025-04-11T17:26:43.693789Z"}},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"(0.21801202, 0.88308203)"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"test_concepts[68], test_llm_concepts[68]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.695880Z","iopub.execute_input":"2025-04-11T17:26:43.696210Z","iopub.status.idle":"2025-04-11T17:26:43.716533Z","shell.execute_reply.started":"2025-04-11T17:26:43.696169Z","shell.execute_reply":"2025-04-11T17:26:43.715291Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"(array([0.2757235 , 0.3548387 , 0.01657918, 0.1384428 , 0.75      ,\n        0.        , 0.75      , 0.        , 1.        , 0.5       ,\n        0.75      , 0.5       , 0.        , 1.        ], dtype=float32),\n array([1., 1., 1., 0., 1., 0., 1., 0.], dtype=float32))"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"c_pred[68], c_pred_llm[68]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.717542Z","iopub.execute_input":"2025-04-11T17:26:43.717919Z","iopub.status.idle":"2025-04-11T17:26:43.738326Z","shell.execute_reply.started":"2025-04-11T17:26:43.717886Z","shell.execute_reply":"2025-04-11T17:26:43.737128Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"(array([ 4.3182704e-03,  9.6764195e-01,  5.7537967e-01,  8.5416883e-02,\n        -6.2954426e-04,  1.1717834e-01,  9.2453039e-01,  3.3428958e-01,\n         4.0201780e-01,  8.4963918e-02,  1.2879211e+00,  7.3506159e-01,\n         8.6507535e-01,  4.3960077e-01], dtype=float32),\n array([0.00997814, 0.9383499 , 0.49504182, 0.2239517 , 0.26834702,\n        0.10256593, 0.7525897 , 0.38319302, 0.3733758 , 0.33430803,\n        1.0112454 , 0.5356499 , 0.4765153 , 0.40466654], dtype=float32))"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test Patient index 18: False positive by Vanilla CBM (0.81), corrected by Enhanced CBM (0.16)","metadata":{}},{"cell_type":"code","source":"y_pred[18], y_pred_llm[18]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.739466Z","iopub.execute_input":"2025-04-11T17:26:43.739855Z","iopub.status.idle":"2025-04-11T17:26:43.758417Z","shell.execute_reply.started":"2025-04-11T17:26:43.739823Z","shell.execute_reply":"2025-04-11T17:26:43.757195Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"(0.8185132, 0.15971082)"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"test_concepts[18], test_llm_concepts[18]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.759567Z","iopub.execute_input":"2025-04-11T17:26:43.759871Z","iopub.status.idle":"2025-04-11T17:26:43.782614Z","shell.execute_reply.started":"2025-04-11T17:26:43.759844Z","shell.execute_reply":"2025-04-11T17:26:43.781345Z"}},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"(array([0.09733607, 0.53629035, 0.12024742, 0.10637413, 0.25      ,\n        0.75      , 0.75      , 0.        , 0.25      , 1.        ,\n        1.        , 1.        , 1.        , 0.        ], dtype=float32),\n array([0., 0., 1., 0., 1., 0., 0., 0.], dtype=float32))"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"c_pred[18], c_pred_llm[18]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.783821Z","iopub.execute_input":"2025-04-11T17:26:43.784216Z","iopub.status.idle":"2025-04-11T17:26:43.805997Z","shell.execute_reply.started":"2025-04-11T17:26:43.784175Z","shell.execute_reply":"2025-04-11T17:26:43.805006Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"(array([0.97301316, 0.415916  , 0.13877705, 0.6551758 , 0.79315317,\n        0.03291085, 0.6848852 , 0.7272564 , 0.87970954, 0.38895974,\n        0.7187521 , 0.84601563, 0.2838308 , 0.8491245 ], dtype=float32),\n array([0.97506374, 0.16642521, 0.38181022, 0.4385682 , 0.50305307,\n        0.13294744, 0.31468448, 0.75940394, 0.55338204, 0.35618755,\n        0.38148788, 1.0313094 , 0.85980856, 0.8719307 ], dtype=float32))"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test Patient index 292: False positive by Vanilla CBM (0.58), corrected by Enhanced CBM (0.01)","metadata":{}},{"cell_type":"code","source":"y_pred[292], y_pred_llm[292]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.807377Z","iopub.execute_input":"2025-04-11T17:26:43.807706Z","iopub.status.idle":"2025-04-11T17:26:43.827609Z","shell.execute_reply.started":"2025-04-11T17:26:43.807676Z","shell.execute_reply":"2025-04-11T17:26:43.826410Z"}},"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"(0.5770642, 0.016563294)"},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"test_concepts[292], test_llm_concepts[292]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.828627Z","iopub.execute_input":"2025-04-11T17:26:43.829049Z","iopub.status.idle":"2025-04-11T17:26:43.849565Z","shell.execute_reply.started":"2025-04-11T17:26:43.829006Z","shell.execute_reply":"2025-04-11T17:26:43.848437Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"(array([0.5377907 , 0.3469709 , 0.63013697, 0.07203941, 0.25      ,\n        1.        , 0.75      , 0.        , 1.        , 1.        ,\n        1.        , 1.        , 0.        , 1.        ], dtype=float32),\n array([0., 0., 0., 1., 1., 0., 0., 0.], dtype=float32))"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"c_pred[292], c_pred_llm[292]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.850698Z","iopub.execute_input":"2025-04-11T17:26:43.851007Z","iopub.status.idle":"2025-04-11T17:26:43.871457Z","shell.execute_reply.started":"2025-04-11T17:26:43.850976Z","shell.execute_reply":"2025-04-11T17:26:43.870271Z"}},"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"(array([0.00972694, 0.9545531 , 0.27013922, 0.3906124 , 1.0037692 ,\n        0.1016365 , 0.72444665, 0.48222154, 0.6749081 , 0.39058012,\n        0.9815534 , 0.8855722 , 0.828193  , 0.98764265], dtype=float32),\n array([0.02630597, 0.90057725, 0.42185712, 0.29580688, 0.52896506,\n        0.10964462, 0.49532697, 0.5687088 , 0.40677857, 0.34187365,\n        0.6538035 , 0.9196273 , 0.9558367 , 0.93371934], dtype=float32))"},"metadata":{}}],"execution_count":89},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### False negative induced by LLM : Patient idx: 220. y_pred 0.75, y_pred_llm 0.35","metadata":{}},{"cell_type":"code","source":"y_pred[220], y_pred_llm[220]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.872633Z","iopub.execute_input":"2025-04-11T17:26:43.873030Z","iopub.status.idle":"2025-04-11T17:26:43.892367Z","shell.execute_reply.started":"2025-04-11T17:26:43.872992Z","shell.execute_reply":"2025-04-11T17:26:43.891005Z"}},"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"(0.74703455, 0.34595966)"},"metadata":{}}],"execution_count":90},{"cell_type":"code","source":"test_concepts[220], test_llm_concepts[220]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.893586Z","iopub.execute_input":"2025-04-11T17:26:43.893886Z","iopub.status.idle":"2025-04-11T17:26:43.916685Z","shell.execute_reply.started":"2025-04-11T17:26:43.893857Z","shell.execute_reply":"2025-04-11T17:26:43.915090Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"(array([0.00494071, 0.37181664, 0.6573202 , 0.10094384, 0.25      ,\n        0.75      , 1.        , 0.        , 0.25      , 0.5       ,\n        1.        , 1.        , 0.        , 1.        ], dtype=float32),\n array([1., 0., 1., 1., 0., 0., 0., 0.], dtype=float32))"},"metadata":{}}],"execution_count":91},{"cell_type":"code","source":"c_pred[220], c_pred_llm[220]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.917858Z","iopub.execute_input":"2025-04-11T17:26:43.918251Z","iopub.status.idle":"2025-04-11T17:26:43.939633Z","shell.execute_reply.started":"2025-04-11T17:26:43.918211Z","shell.execute_reply":"2025-04-11T17:26:43.938534Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"(array([ 0.01239062,  0.93275696, -0.14583707,  0.40342084,  1.2448468 ,\n         0.07405382,  0.34092572,  0.30931085,  0.5295471 ,  0.46710438,\n         0.5368258 ,  0.5181605 ,  0.526659  ,  0.9723195 ], dtype=float32),\n array([0.03989143, 0.905798  , 0.04206815, 0.25330007, 0.37598324,\n        0.11872354, 0.09648513, 0.3908201 , 0.25059545, 0.28901613,\n        0.19863881, 0.47037488, 0.56393766, 0.8122095 ], dtype=float32))"},"metadata":{}}],"execution_count":92},{"cell_type":"markdown","source":"#### Interventions over LLM concepts: 0,5 helps flip the prediction to 0.96","metadata":{}},{"cell_type":"code","source":"hospital_test.values[62]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.940619Z","iopub.execute_input":"2025-04-11T17:26:43.940916Z","iopub.status.idle":"2025-04-11T17:26:43.962216Z","shell.execute_reply.started":"2025-04-11T17:26:43.940889Z","shell.execute_reply":"2025-04-11T17:26:43.961009Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"array([26689168])"},"metadata":{}}],"execution_count":93},{"cell_type":"markdown","source":"### False positive induced by LLM : Patient idx: 23. y_pred 0.33, y_pred_llm 0.62","metadata":{}},{"cell_type":"code","source":"y_pred[23], y_pred_llm[23]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.963303Z","iopub.execute_input":"2025-04-11T17:26:43.963693Z","iopub.status.idle":"2025-04-11T17:26:43.989994Z","shell.execute_reply.started":"2025-04-11T17:26:43.963663Z","shell.execute_reply":"2025-04-11T17:26:43.988919Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"(0.33968437, 0.6174557)"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"test_concepts[23], test_llm_concepts[23]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:43.991152Z","iopub.execute_input":"2025-04-11T17:26:43.991530Z","iopub.status.idle":"2025-04-11T17:26:44.014829Z","shell.execute_reply.started":"2025-04-11T17:26:43.991472Z","shell.execute_reply":"2025-04-11T17:26:44.013867Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"(array([0.0379902 , 0.43548387, 0.00151751, 0.04754601, 0.75      ,\n        0.75      , 0.25      , 0.        , 0.75      , 1.        ,\n        0.25      , 0.25      , 0.        , 1.        ], dtype=float32),\n array([1., 0., 0., 0., 1., 0., 1., 0.], dtype=float32))"},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"c_pred[23], c_pred_llm[23]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.016194Z","iopub.execute_input":"2025-04-11T17:26:44.016625Z","iopub.status.idle":"2025-04-11T17:26:44.038908Z","shell.execute_reply.started":"2025-04-11T17:26:44.016586Z","shell.execute_reply":"2025-04-11T17:26:44.037926Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"(array([6.4669648e-06, 9.9764013e-01, 2.9346308e-01, 6.2470776e-01,\n        9.9923730e-02, 1.1631797e-01, 6.4368671e-01, 5.6948900e-01,\n        2.7011672e-01, 2.2627078e-02, 8.0953360e-01, 1.0250344e+00,\n        3.9424908e-01, 2.3547758e-01], dtype=float32),\n array([ 4.6256595e-05,  9.9412584e-01,  1.4053696e-01,  3.9067748e-01,\n         1.2237266e-01,  1.7104834e-02,  3.6746442e-01,  6.2385708e-01,\n        -2.6818430e-01,  9.3596555e-02,  4.5362547e-01,  9.0374184e-01,\n         3.2077765e-01,  2.0075791e-01], dtype=float32))"},"metadata":{}}],"execution_count":96},{"cell_type":"markdown","source":"#### Interventions over LLM concepts: 0,2,6 helps flip the prediction to 0.05 ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"count = 0\ntotal = 0\n\nfor a in false_negatives_idx_llm:\n    b = c_pred_llm[a].copy()\n    \n    b[12] = test_concepts[a][12]\n    #b[13] = test_concepts[a][13]\n    b = b[-2:]\n    \n    with torch.no_grad():\n        p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int>=0.5:\n        count+=1\n        print(a,p_int)\n    total+=1\n    \nprint(\"False negatives corrections:\",count/total,count,total)\n\ncount = 0\ntotal = 0\n\nfor a in false_positives_idx_llm:\n    b = c_pred_llm[a].copy()\n\n    b[12] = test_concepts[a][12]\n    #b[13] = test_concepts[a][13]\n    \n    b = b[-2:]\n    \n    with torch.no_grad():\n        p_int = model_int3(torch.tensor(test_features[a:a+1]),torch.tensor([b]).float(),torch.tensor(test_llm_concepts[a:a+1]))\n\n    if p_int<=0.5:\n        count+=1\n        print(a,p_int)\n    total+=1\n\n    \nprint(\"False positives corrections:\",count/total,count,total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.040145Z","iopub.execute_input":"2025-04-11T17:26:44.040565Z","iopub.status.idle":"2025-04-11T17:26:44.104334Z","shell.execute_reply.started":"2025-04-11T17:26:44.040527Z","shell.execute_reply":"2025-04-11T17:26:44.103198Z"}},"outputs":[{"name":"stdout","text":"16 tensor([[0.5618]])\n62 tensor([[0.8271]])\n128 tensor([[0.6912]])\n158 tensor([[0.6374]])\n182 tensor([[0.6879]])\n191 tensor([[0.8102]])\n226 tensor([[0.7771]])\n281 tensor([[0.7602]])\n331 tensor([[0.5086]])\n374 tensor([[0.7195]])\nFalse negatives corrections: 0.45454545454545453 10 22\n22 tensor([[0.4052]])\n42 tensor([[0.4588]])\n54 tensor([[0.4076]])\n83 tensor([[0.3004]])\n171 tensor([[0.2252]])\n214 tensor([[0.3866]])\n327 tensor([[0.4791]])\nFalse positives corrections: 0.12727272727272726 7 55\n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Patient idx 62: Correction of FN by flipping vanilla concept 12","metadata":{}},{"cell_type":"code","source":"y_pred[62], y_pred_llm[62], y_true[62]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.105834Z","iopub.execute_input":"2025-04-11T17:26:44.106211Z","iopub.status.idle":"2025-04-11T17:26:44.113553Z","shell.execute_reply.started":"2025-04-11T17:26:44.106172Z","shell.execute_reply":"2025-04-11T17:26:44.111674Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-98-2eb72c90531f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    y_pred[62], y_pred_llm[62], y_true[62], hospital_test[]\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-98-2eb72c90531f>, line 1)","output_type":"error"}],"execution_count":98},{"cell_type":"code","source":"test_concepts[191], test_llm_concepts[191]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.114227Z","iopub.status.idle":"2025-04-11T17:26:44.114735Z","shell.execute_reply":"2025-04-11T17:26:44.114520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"c_pred[191], c_pred_llm[191]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.115608Z","iopub.status.idle":"2025-04-11T17:26:44.116033Z","shell.execute_reply":"2025-04-11T17:26:44.115835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Patient idx 171: Correction of FN by flipping vanilla concept 12","metadata":{}},{"cell_type":"code","source":"y_pred[171], y_pred_llm[171]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.117312Z","iopub.status.idle":"2025-04-11T17:26:44.117800Z","shell.execute_reply":"2025-04-11T17:26:44.117601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_concepts[171], test_llm_concepts[171]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.118780Z","iopub.status.idle":"2025-04-11T17:26:44.119250Z","shell.execute_reply":"2025-04-11T17:26:44.119039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"c_pred[171], c_pred_llm[171]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.119940Z","iopub.status.idle":"2025-04-11T17:26:44.120394Z","shell.execute_reply":"2025-04-11T17:26:44.120206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred[8], y_pred_llm[8], y_true[8]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:26:44.121506Z","iopub.status.idle":"2025-04-11T17:26:44.121951Z","shell.execute_reply":"2025-04-11T17:26:44.121764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}